{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from typing import Dict, List\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize,normalize\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage import zoom\n",
    "from functools import reduce\n",
    "from scipy.io import loadmat\n",
    "from skimage.measure import block_reduce\n",
    "from collections import Counter\n",
    "from scipy.sparse import coo_matrix,hstack, vstack\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.ops as ops\n",
    "torch.cuda.set_device(2)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585 / 585 The length of trainset is 585\n",
      "65 / 65 The length of testset is 65\n",
      "Completed data handle in 96 seconds\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "root_dir = '/data/fjsdata/MCBIR-Ins/origa650/' #the path of images\n",
    "trData = pd.read_csv(root_dir+\"trainset.csv\" , sep=',')\n",
    "teData = pd.read_csv(root_dir+\"testset.csv\" , sep=',')\n",
    "#trainset \n",
    "trN, trI, trM, trY = [],[],[],[]\n",
    "for iname, itype in np.array(trData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        trN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            trY.append(1)\n",
    "        else: trY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        trI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        trM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "#testset\n",
    "teN, teI, teM, teY = [],[],[],[]\n",
    "for iname, itype in np.array(teData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        teN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            teY.append(1)\n",
    "        else: teY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        teI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        teM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes=2, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfgs = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "def vgg11(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") from\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['A'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg11_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['A'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['B'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['B'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['D'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['D'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration \"E\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['E'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['E'], batch_norm=True), **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59 / 59 : loss = 0.3352225Eopch:     1 mean_loss = 5.554219\n",
      " 59 / 59 : loss = 0.674617Eopch:     2 mean_loss = 0.889816\n",
      " 59 / 59 : loss = 0.581112Eopch:     3 mean_loss = 0.668045\n",
      " 59 / 59 : loss = 0.313654Eopch:     4 mean_loss = 0.596518\n",
      " 59 / 59 : loss = 0.763212Eopch:     5 mean_loss = 0.607837\n",
      " 59 / 59 : loss = 0.379776Eopch:     6 mean_loss = 0.612159\n",
      " 59 / 59 : loss = 0.620648Eopch:     7 mean_loss = 0.609942\n",
      " 59 / 59 : loss = 0.578079Eopch:     8 mean_loss = 0.726678\n",
      " 59 / 59 : loss = 0.496349Eopch:     9 mean_loss = 0.633895\n",
      " 59 / 59 : loss = 0.719556Eopch:    10 mean_loss = 0.631501\n",
      "best_loss = 0.596518\n",
      " 6 / 7 Sensitivity(TPR) of Normal: 1.000000\n",
      "Sensitivity(TPR) of Glaucoma: 0.000000\n",
      "AUC (Area Under Curve) of Micro: 0.584184\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define model\n",
    "model = vgg16_bn().cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define cross-entropy loss\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trI)))\n",
    "    trI_batch = np.array(trI)[shuffled_idx]\n",
    "    trY_batch = np.array(trY)[shuffled_idx]\n",
    "    num_batches = len(trI) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(trI_batch[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_batch[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        Out_batch = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = ce_loss(Out_batch,Y_batch)#loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()#update parameters\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#test model\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    prob = out_batch.max(1,keepdim=True)[0]\n",
    "    teY_prob.extend(prob.cpu().data.numpy().tolist())\n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().flatten().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#TNR= TN / (FP+TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR= TP / (TP+FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC curves: y axis:Sensitivity, x axis:1-Specificity\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print ('Sensitivity(TPR) of Normal: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of Glaucoma: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "#plot roc curve\n",
    "fpr_tce, tpr_tce, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) \n",
    "#plt.plot(fpr_ce, tpr_ce, c = 'r', ls = '--', label = u'ATH(our) AUC=%.4f' % auc_score)\n",
    "plt.plot(fpr_tce, tpr_tce, c = 'b', ls = '--', label = u'R-MAC AUC=%.4f' % auc_score) \n",
    "plt.plot((0, 1), (0, 1), c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.2))\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.grid(b=True, ls=':')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Fundus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory and save model in CPU\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "best_net = best_net.cpu()\n",
    "torch.cuda.empty_cache() \n",
    "torch.save(best_net.state_dict(), '/data/tmpexec/BLCF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing PCA-w...\n",
      "DONE! 0.84s\n",
      "Fitting vocabulary\n",
      "DONE! 244.25s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Code: https://github.com/imatge-upc/salbow/tree/master/src/BLCF\n",
    "       https://github.com/imatge-upc/retrieval-2016-icmr\n",
    "#Paper: CBMI2018《Saliency Weighted Convolutional Features for Instance Search》\n",
    "        ICMR2016《Bags of local convolutional features for scalable instance search》\n",
    "'''\n",
    "\n",
    "#load model and transfer to GPU\n",
    "device = torch.device(\"cuda\")\n",
    "best_net = vgg16_bn()\n",
    "best_net.load_state_dict(torch.load( '/data/tmpexec/BLCF.pkl'))\n",
    "best_net.to(device)\n",
    "#1. Extract features based on backbone and Aggregate R-MAC\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "best_net.features.register_forward_hook(get_activation('features'))\n",
    "\n",
    "# get codebook\n",
    "def get_codebook(ConvFeat, n_clusters=1000, n_components=100):\n",
    "    \"\"\"\n",
    "    Compute PCA and codebook models\n",
    "    arg: n_clusters --  size of vocabulary\n",
    "         n_components -- dim PCA model / None if not computing PCA\n",
    "    \"\"\"\n",
    "    print (\"computing PCA-w...\")\n",
    "    training_feats  = []\n",
    "    for i in range(len(ConvFeat)):\n",
    "        feat = np.transpose( np.array(ConvFeat[i]), (1,2,0) )\n",
    "        r, c, ch = feat.shape\n",
    "        feat = np.reshape( feat, (r*c, -1) )\n",
    "        training_feats.extend(feat)\n",
    "    training_feats = np.array(training_feats)\n",
    "    training_feats = normalize(training_feats)\n",
    "    t0 = time.time()\n",
    "    pca_model = PCA(n_components, whiten=True)\n",
    "    pca_model.fit(training_feats)\n",
    "    t1 = time.time()\n",
    "    print (\"DONE! %.2fs\" % (t1-t0))\n",
    "\n",
    "    training_feats = pca_model.transform(training_feats)\n",
    "    print (\"Fitting vocabulary\")\n",
    "    t0 = time.time()\n",
    "    kmeans =KMeans(n_clusters=n_clusters, random_state=0).fit(training_feats)\n",
    "    t1 = time.time()\n",
    "    print (\"DONE! %.2fs\" % (t1-t0))\n",
    "\n",
    "    return pca_model, kmeans #kmeans.cluster_centers_\n",
    "\n",
    "batchSize=10\n",
    "trF = []\n",
    "num_batches = len(trI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    feat_batch = activation['features'].squeeze()\n",
    "    trF.extend(feat_batch.cpu().numpy().tolist())\n",
    "    \n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    feat_batch = activation['features'].squeeze()\n",
    "    teF.extend(feat_batch.cpu().numpy().tolist())\n",
    "    \n",
    "pca_model, kmeans = get_codebook(trF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(585, 1000)\n",
      "(65, 1000)\n",
      "Completed buliding index in 1 seconds\n",
      "mAP=0.4520, mIoU=0.7197\n"
     ]
    }
   ],
   "source": [
    "def get_bow( assignments, weights, n=1000):\n",
    "    '''\n",
    "    Funtion to build BoW representation given an assignment map.\n",
    "    args:\n",
    "        assignments - 2D map with assignments associated to each local feature\n",
    "        weights     - 2D maps with normalized (0-1) spatial weighting scheme\n",
    "        n           - size of the visual vocabulary (default 1000)\n",
    "    '''\n",
    "    # sparse encoding !\n",
    "    rows = np.array([], dtype=np.int)\n",
    "    cols = np.array([], dtype=np.int)\n",
    "    vals = np.array([], dtype=np.float)\n",
    "    n_docs = 0\n",
    "\n",
    "    # get counts\n",
    "    cnt = Counter(assignments.flatten())\n",
    "    ids = list(cnt.keys())#np.array(cnt.keys())\n",
    "    weights = weights.flatten()\n",
    "    weights = np.array([weights[np.where(assignments.flatten()==i)[0]].sum() for i in ids])\n",
    "\n",
    "    #save index\n",
    "    cols = np.append( cols, np.array(ids).astype(int) )\n",
    "    rows = np.append( rows, np.ones( len(cnt.keys()), dtype=int )*n_docs )\n",
    "    vals = np.append( vals, weights.astype(float) )\n",
    "    n_docs +=1\n",
    "\n",
    "    bow = coo_matrix( ( vals, (rows, cols) ), shape=(n_docs,n) )\n",
    "    bow = bow.tocsr()\n",
    "    #    bow = normalize(bow)\n",
    "    return bow\n",
    "#trainset\n",
    "for i in range(len(trF)):\n",
    "    feat = np.array(trF[i])\n",
    "    mask = np.array(trI[i])\n",
    "    #assignments maps\n",
    "    #feat = zoom(feat, (1,32,32), order=1) #interpolate=256/8=32\n",
    "    feat = np.reshape( feat, (feat.shape[0], -1) )\n",
    "    feat = np.transpose( feat, (1,0) )\n",
    "    feat = normalize(feat)\n",
    "    feat = pca_model.transform(feat)\n",
    "    feat = normalize(feat)\n",
    "    assigns = kmeans.predict(feat)\n",
    "    #Normalized saliency\n",
    "    mask = block_reduce( mask[:,:,0], (32,32), np.max )#downsample\n",
    "    mask = mask.astype(np.float32)\n",
    "    if not np.any(mask):\n",
    "        mask[...]=1\n",
    "    mask = mask / mask.max()\n",
    "    #get bags of words\n",
    "    bow = get_bow(assigns, mask)\n",
    "    if i == 0:\n",
    "        tr_bow = bow\n",
    "    else:\n",
    "        tr_bow = vstack( [tr_bow, bow] )\n",
    "tr_bow = normalize(tr_bow)\n",
    "print(tr_bow.shape)\n",
    "#testset\n",
    "for i in range(len(teF)):\n",
    "    feat = np.array(teF[i])\n",
    "    mask = np.array(teI[i])\n",
    "    #assignments maps\n",
    "    #feat = zoom(feat, (1,32,32), order=1) #interpolate=256/8=32\n",
    "    feat = np.reshape( feat, (feat.shape[0], -1) )\n",
    "    feat = np.transpose( feat, (1,0) )\n",
    "    feat = normalize(feat)\n",
    "    feat = pca_model.transform(feat)\n",
    "    feat = normalize(feat)\n",
    "    assigns = kmeans.predict(feat)\n",
    "    #Normalized saliency\n",
    "    mask = block_reduce( mask[:,:,0], (32,32), np.max )#downsample\n",
    "    mask = mask.astype(np.float32)\n",
    "    if not np.any(mask):\n",
    "        mask[...]=1\n",
    "    mask = mask / mask.max()\n",
    "    #get bags of words\n",
    "    bow = get_bow(assigns, mask)\n",
    "    if i == 0:\n",
    "        te_bow = bow\n",
    "    else:\n",
    "        te_bow = vstack( [te_bow, bow] )\n",
    "te_bow = normalize(te_bow)\n",
    "print(te_bow.shape)\n",
    "\n",
    "#evaluate\n",
    "#compute the size of lesion\n",
    "def Func_IOU_size(pred,target,n_classes = 3 ):\n",
    "    ious = []\n",
    "    # ignore IOU for background class\n",
    "    for cls in range(1,n_classes):\n",
    "        pred_inds = pred == cls\n",
    "        pred_sum = pred_inds.sum()\n",
    "        target_inds = target == cls\n",
    "        target_sum = target_inds.sum()\n",
    "        ious.append(round(float(min(pred_sum,target_sum)/max(pred_sum,target_sum)),4))\n",
    "    return np.mean(ious)\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(1000) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(tr_bow.toarray(), dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [5, 10, 20, 50]:\n",
    "    mAP = [] #mean average precision\n",
    "    mIoU = []\n",
    "    scores, neighbors = gpu_index.search(te_bow.toarray().astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(te_bow.toarray().tolist()):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "            mIoU.append(Func_IOU_size(teM[i],trM[j]))\n",
    "    print(\"mAP={:.4f}, mIoU={:.4f}\".format(np.mean(mAP),np.mean(mIoU)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = best_net.cpu()\n",
    "x_batch = x_batch.cpu()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--------below is the dataset split code and image show code--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    482\n",
      "True     168\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    433\n",
      "True     152\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    49\n",
      "True     16\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "datas = pd.read_csv(root_dir+\"labels.csv\" , sep=',')\n",
    "datas = datas[['filename','diagnosis(glaucoma=True)']]\n",
    "print(datas['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData, teData = train_test_split(datas, test_size=0.1) #split trainset and testset\n",
    "print(trData['diagnosis(glaucoma=True)'].value_counts())\n",
    "print(teData['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/trainset.csv',index=False)\n",
    "teData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/testset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
