{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from typing import Dict, List\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "from functools import reduce\n",
    "from scipy.io import loadmat\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.ops as ops\n",
    "torch.cuda.set_device(0)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585 / 585 The length of trainset is 585\n",
      "65 / 65 The length of testset is 65\n",
      "Completed data handle in 96 seconds\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "root_dir = '/data/fjsdata/MCBIR-Ins/origa650/' #the path of images\n",
    "trData = pd.read_csv(root_dir+\"trainset.csv\" , sep=',')\n",
    "teData = pd.read_csv(root_dir+\"testset.csv\" , sep=',')\n",
    "#trainset \n",
    "trN, trI, trM, trY = [],[],[],[]\n",
    "for iname, itype in np.array(trData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        trN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            trY.append(1)\n",
    "        else: trY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        trI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        trM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "#testset\n",
    "teN, teI, teM, teY = [],[],[],[]\n",
    "for iname, itype in np.array(teData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        teN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            teY.append(1)\n",
    "        else: teY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        teI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        teM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes=2, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfgs = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "def vgg11(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") from\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['A'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg11_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['A'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['B'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['B'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['D'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['D'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration \"E\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['E'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['E'], batch_norm=True), **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59 / 59 : loss = 5.4172877Eopch:     1 mean_loss = 8.076637\n",
      " 59 / 59 : loss = 0.639894Eopch:     2 mean_loss = 1.093184\n",
      " 59 / 59 : loss = 0.696462Eopch:     3 mean_loss = 0.708317\n",
      " 59 / 59 : loss = 0.370654Eopch:     4 mean_loss = 0.605409\n",
      " 59 / 59 : loss = 1.047436Eopch:     5 mean_loss = 0.628696\n",
      " 59 / 59 : loss = 0.409059Eopch:     6 mean_loss = 0.610717\n",
      " 59 / 59 : loss = 0.431324Eopch:     7 mean_loss = 0.624869\n",
      " 59 / 59 : loss = 0.765612Eopch:     8 mean_loss = 0.631856\n",
      " 59 / 59 : loss = 0.525404Eopch:     9 mean_loss = 0.612008\n",
      " 59 / 59 : loss = 0.573079Eopch:    10 mean_loss = 0.595682\n",
      "best_loss = 0.595682\n",
      " 6 / 7 Sensitivity(TPR) of Normal: 1.000000\n",
      "Sensitivity(TPR) of Glaucoma: 0.000000\n",
      "AUC (Area Under Curve) of Micro: 0.593112\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define model\n",
    "model = vgg16_bn().cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define cross-entropy loss\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trI)))\n",
    "    trI_batch = np.array(trI)[shuffled_idx]\n",
    "    trY_batch = np.array(trY)[shuffled_idx]\n",
    "    num_batches = len(trI) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(trI_batch[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_batch[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        Out_batch = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = ce_loss(Out_batch,Y_batch)#loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()#update parameters\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#test model\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    prob = out_batch.max(1,keepdim=True)[0]\n",
    "    teY_prob.extend(prob.cpu().data.numpy().tolist())\n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().flatten().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#TNR= TN / (FP+TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR= TP / (TP+FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC curves: y axis:Sensitivity, x axis:1-Specificity\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print ('Sensitivity(TPR) of Normal: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of Glaucoma: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "#plot roc curve\n",
    "fpr_tce, tpr_tce, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) \n",
    "#plt.plot(fpr_ce, tpr_ce, c = 'r', ls = '--', label = u'ATH(our) AUC=%.4f' % auc_score)\n",
    "plt.plot(fpr_tce, tpr_tce, c = 'b', ls = '--', label = u'R-MAC AUC=%.4f' % auc_score) \n",
    "plt.plot((0, 1), (0, 1), c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.2))\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.grid(b=True, ls=':')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Fundus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory and save model in CPU\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "best_net = best_net.cpu()\n",
    "torch.cuda.empty_cache() \n",
    "torch.save(best_net.state_dict(), '/data/tmpexec/CroW.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Code: https://github.com/PyRetri/PyRetri\n",
    "       https://github.com/YahooArchive/crow\n",
    "#Paper: ECCV2017《Cross-dimensional Weighting for Aggregated Deep Convolutional Features》\n",
    "'''\n",
    "class CroW():\n",
    "    \"\"\"\n",
    "    Cross-dimensional Weighting for Aggregated Deep Convolutional Features.\n",
    "    c.f. https://arxiv.org/pdf/1512.04065.pdf\n",
    "    Args:\n",
    "        spatial_a (float): hyper-parameter for calculating spatial weight.\n",
    "        spatial_b (float): hyper-parameter for calculating spatial weight.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, spatial_a=2.0, spatial_b=2.0):\n",
    "       \n",
    "        self.first_show = True\n",
    "        self.spatial_a = spatial_a\n",
    "        self.spatial_b = spatial_b\n",
    "\n",
    "    def __call__(self, fea:torch.tensor) -> torch.tensor:\n",
    "        final_fea = None\n",
    "        if fea.ndimension() == 4:\n",
    "            spatial_weight = fea.sum(dim=1, keepdim=True)\n",
    "            z = (spatial_weight ** self.spatial_a).sum(dim=(2, 3), keepdim=True)\n",
    "            z = z ** (1.0 / self.spatial_a)\n",
    "            spatial_weight = (spatial_weight / z) ** (1.0 / self.spatial_b)\n",
    "\n",
    "            c, w, h = fea.shape[1:]\n",
    "            nonzeros = (fea!=0).float().sum(dim=(2, 3)) / 1.0 / (w * h) + 1e-6\n",
    "            channel_weight = torch.log(nonzeros.sum(dim=1, keepdim=True) / nonzeros)\n",
    "\n",
    "            fea = fea * spatial_weight\n",
    "            fea = fea.sum(dim=(2, 3))\n",
    "            fea = fea * channel_weight\n",
    "            \n",
    "            final_fea = fea\n",
    "\n",
    "        else:# In case of fc feature.\n",
    "            assert fea.ndimension() == 2\n",
    "            if self.first_show:\n",
    "                print(\"[Crow Aggregator]: find 2-dimension feature map, skip aggregation\")\n",
    "                self.first_show = False\n",
    "            final_fea = fea\n",
    "            \n",
    "        return final_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed buliding index in 23 seconds\n",
      "mAP=0.5223, mIoU=0.7121\n",
      "mAP=0.4681, mIoU=0.7100\n",
      "mAP=0.4471, mIoU=0.7093\n",
      "mAP=0.4366, mIoU=0.7144\n"
     ]
    }
   ],
   "source": [
    "#load model and transfer to GPU\n",
    "device = torch.device(\"cuda\")\n",
    "best_net = vgg16_bn()\n",
    "best_net.load_state_dict(torch.load( '/data/tmpexec/CroW.pkl'))\n",
    "best_net.to(device)\n",
    "#1. Extract features based on backbone and Aggregate R-MAC\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "best_net.features.register_forward_hook(get_activation('features'))\n",
    "\n",
    "batchSize=10\n",
    "crow = CroW()\n",
    "trF = []\n",
    "num_batches = len(trI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    feat_batch = activation['features'].squeeze()\n",
    "    feat_ret_batch = crow(feat_batch)\n",
    "    trF.extend(feat_ret_batch.cpu().numpy().tolist())\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    feat_batch = activation['features'].squeeze()\n",
    "    feat_ret_batch = crow(feat_batch)\n",
    "    teF.extend(feat_ret_batch.cpu().numpy().tolist())\n",
    "    \n",
    "#compute the size of lesion\n",
    "def Func_IOU_size(pred,target,n_classes = 3 ):\n",
    "    ious = []\n",
    "    # ignore IOU for background class\n",
    "    for cls in range(1,n_classes):\n",
    "        pred_inds = pred == cls\n",
    "        pred_sum = pred_inds.sum()\n",
    "        target_inds = target == cls\n",
    "        target_sum = target_inds.sum()\n",
    "        ious.append(round(float(min(pred_sum,target_sum)/max(pred_sum,target_sum)),4))\n",
    "    return np.mean(ious)\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(512) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [5, 10, 20, 50]:\n",
    "    mAP = [] #mean average precision\n",
    "    mIoU = []\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "            mIoU.append(Func_IOU_size(teM[i],trM[j],n_classes=3))\n",
    "    print(\"mAP={:.4f}, mIoU={:.4f}\".format(np.mean(mAP),np.mean(mIoU)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = best_net.cpu()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--------below is the dataset split code and image show code--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    482\n",
      "True     168\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    433\n",
      "True     152\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    49\n",
      "True     16\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "datas = pd.read_csv(root_dir+\"labels.csv\" , sep=',')\n",
    "datas = datas[['filename','diagnosis(glaucoma=True)']]\n",
    "print(datas['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData, teData = train_test_split(datas, test_size=0.1) #split trainset and testset\n",
    "print(trData['diagnosis(glaucoma=True)'].value_counts())\n",
    "print(teData['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/trainset.csv',index=False)\n",
    "teData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/testset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
