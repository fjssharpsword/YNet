{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from typing import Dict, List\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "from sklearn.decomposition import PCA\n",
    "from functools import reduce\n",
    "from scipy.io import loadmat\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.ops as ops\n",
    "torch.cuda.set_device(0)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585 / 585 The length of trainset is 585\n",
      "65 / 65 The length of testset is 65\n",
      "Completed data handle in 96 seconds\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "root_dir = '/data/fjsdata/MCBIR-Ins/origa650/' #the path of images\n",
    "trData = pd.read_csv(root_dir+\"trainset.csv\" , sep=',')\n",
    "teData = pd.read_csv(root_dir+\"testset.csv\" , sep=',')\n",
    "#trainset \n",
    "trN, trI, trM, trY = [],[],[],[]\n",
    "for iname, itype in np.array(trData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        trN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            trY.append(1)\n",
    "        else: trY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        trI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        trM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "#testset\n",
    "teN, teI, teM, teY = [],[],[],[]\n",
    "for iname, itype in np.array(teData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        teN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            teY.append(1)\n",
    "        else: teY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        teI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        teM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        feat = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(feat)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return feat, x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59 / 59 : loss = 0.653479Eopch:     1 mean_loss = 0.747596\n",
      " 59 / 59 : loss = 0.317225Eopch:     2 mean_loss = 0.614158\n",
      " 59 / 59 : loss = 0.178564Eopch:     3 mean_loss = 0.588383\n",
      " 59 / 59 : loss = 1.039339Eopch:     4 mean_loss = 0.594886\n",
      " 59 / 59 : loss = 0.725242Eopch:     5 mean_loss = 0.595137\n",
      " 59 / 59 : loss = 0.857743Eopch:     6 mean_loss = 0.570492\n",
      " 59 / 59 : loss = 0.472885Eopch:     7 mean_loss = 0.579540\n",
      " 59 / 59 : loss = 0.473867Eopch:     8 mean_loss = 0.575807\n",
      " 59 / 59 : loss = 0.582568Eopch:     9 mean_loss = 0.554884\n",
      " 59 / 59 : loss = 0.330175Eopch:    10 mean_loss = 0.582918\n",
      "best_loss = 0.554884\n",
      " 6 / 7 Sensitivity(TPR) of Normal: 1.000000\n",
      "Sensitivity(TPR) of Glaucoma: 0.000000\n",
      "AUC (Area Under Curve) of Micro: 0.390306\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define model\n",
    "model = resnet50(num_classes=2).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define cross-entropy loss\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trI)))\n",
    "    trI_batch = np.array(trI)[shuffled_idx]\n",
    "    trY_batch = np.array(trY)[shuffled_idx]\n",
    "    num_batches = len(trI) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(trI_batch[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_batch[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        _,Out_batch = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = ce_loss(Out_batch,Y_batch)#loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()#update parameters\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#test model\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    _,out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    prob = out_batch.max(1,keepdim=True)[0]\n",
    "    teY_prob.extend(prob.cpu().data.numpy().tolist())\n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().flatten().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#TNR= TN / (FP+TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR= TP / (TP+FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC curves: y axis:Sensitivity, x axis:1-Specificity\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print ('Sensitivity(TPR) of Normal: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of Glaucoma: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "#plot roc curve\n",
    "fpr_tce, tpr_tce, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) \n",
    "#plt.plot(fpr_ce, tpr_ce, c = 'r', ls = '--', label = u'ATH(our) AUC=%.4f' % auc_score)\n",
    "plt.plot(fpr_tce, tpr_tce, c = 'b', ls = '--', label = u'R-MAC AUC=%.4f' % auc_score) \n",
    "plt.plot((0, 1), (0, 1), c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.2))\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.grid(b=True, ls=':')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Fundus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory and save model in CPU\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "best_net = best_net.cpu()\n",
    "torch.cuda.empty_cache() \n",
    "torch.save(best_net.state_dict(), '/data/tmpexec/CAM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(585, 2048)\n",
      "Computing PCA with dimension reduction to:  512\n",
      "(512, 2048)\n",
      "PCA finished!\n",
      "Time elapsed computing PCA:  0.14826226234436035\n",
      "Completed buliding index in 23 seconds\n",
      "mAP=0.5917, mIoU=0.7287\n",
      "mAP=0.5435, mIoU=0.7150\n",
      "mAP=0.4982, mIoU=0.7152\n",
      "mAP=0.4609, mIoU=0.7114\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Code: https://github.com/imatge-upc/retrieval-2017-cam\n",
    "#Paper: BMVC2017《Class-Weighted Convolutional Features for Image Retrieval》\n",
    "'''\n",
    "# Extract region of interest from CAMs\n",
    "def extract_ROI(heatmap, threshold):\n",
    "    th = threshold * np.max(heatmap)\n",
    "    heatmap = heatmap > th\n",
    "    # Find the largest connected component\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(heatmap.astype('uint8'), mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    areas = [cv2.contourArea(ctr) for ctr in contours]\n",
    "\n",
    "    max_contour = contours[areas.index(max(areas))]\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(max_contour)\n",
    "    if w == 0:\n",
    "        w = heatmap.shape[1]\n",
    "    if h == 0:\n",
    "        h = heatmap.shape[0]\n",
    "    return x, y, w, h\n",
    "\n",
    "def compute_crow_channel_weight(X):\n",
    "    \"\"\"\n",
    "    Given a tensor of features, compute channel weights as the\n",
    "    log of inverse channel sparsity.\n",
    "    :param ndarray X:\n",
    "        3d tensor of activations with dimensions (channels, height, width)\n",
    "    :returns ndarray:\n",
    "        a channel weight vector\n",
    "    \"\"\"\n",
    "    K, w, h = X.shape\n",
    "    area = float(w * h)\n",
    "    nonzeros = np.zeros(K, dtype=np.float32)\n",
    "    for i, x in enumerate(X):\n",
    "        nonzeros[i] = np.count_nonzero(x) / area\n",
    "\n",
    "    nzsum = nonzeros.sum()\n",
    "    for i, d in enumerate(nonzeros):\n",
    "        nonzeros[i] = np.log(nzsum / d) if d > 0. else 0.\n",
    "\n",
    "    return nonzeros\n",
    "\n",
    "def compute_pca(descriptors, pca_dim=512, whiten=True):\n",
    "    print (descriptors.shape)\n",
    "    t1 = time.time()\n",
    "    print( 'Computing PCA with dimension reduction to: ', pca_dim)\n",
    "    sys.stdout.flush()\n",
    "    pca = PCA(n_components=pca_dim, whiten=whiten)\n",
    "    pca.fit(descriptors)\n",
    "    print (pca.components_.shape)\n",
    "    print ('PCA finished!')\n",
    "    print ('Time elapsed computing PCA: ', time.time() - t1)\n",
    "    return pca\n",
    "\n",
    "\n",
    "def sum_pooling(features):\n",
    "    num_samples = features.shape[0]\n",
    "    num_features = features.shape[1]\n",
    "    sys.stdout.flush()\n",
    "    descriptors = np.zeros((num_samples, num_features), dtype=np.float32)\n",
    "    for i in range(0, num_samples):\n",
    "        #print 'Image: ', i\n",
    "        #sys.stdout.flush()\n",
    "        for f in range(0, num_features):\n",
    "            descriptors[i, f] = features[i, f].sum()\n",
    "    descriptors /= np.linalg.norm(descriptors, axis=1)[:, None]\n",
    "    return descriptors\n",
    "\n",
    "def weighted_cam_pooling(features, cams, max_pool=False, channel_weights=True):\n",
    "    '''\n",
    "    :param features: Feature Maps\n",
    "    :param cams: Class Activation Maps\n",
    "    :param max_pool: Perform also Max pooling\n",
    "    :param channel_weights: Channel Weighting as in Crow\n",
    "    :return: A descriptor for each CAM.\n",
    "    '''\n",
    "    t = time.time()\n",
    "    num_samples = features.shape[0]\n",
    "    num_features = features.shape[1]\n",
    "    num_classes = cams.shape[1]\n",
    "\n",
    "    wp_regions = np.zeros((num_features, num_classes), dtype=np.float32)\n",
    "    wsp_descriptors_reg = np.zeros((num_samples * num_classes, num_features), dtype=np.float32)\n",
    "    wmp_descriptors_reg = np.zeros((num_samples * num_classes, num_features), dtype=np.float32)\n",
    "\n",
    "    if max_pool:\n",
    "        mp_regions = np.zeros((num_features, num_classes), dtype=np.float32)\n",
    "\n",
    "    for i in range(0, num_samples):\n",
    "        #CROW\n",
    "        if channel_weights:\n",
    "            C = np.array(compute_crow_channel_weight(features[i]))\n",
    "\n",
    "        for f in range(0, num_features):\n",
    "            for k in range(0, num_classes):\n",
    "                # For each region compute avg weighted sum of activations and l2 normalize\n",
    "                if max_pool:\n",
    "                        mp_regions[f, k] = np.amax(np.multiply(features[i, f], cams[i, k]))\n",
    "                wp_regions[f, k] = np.multiply(features[i, f], cams[i, k]).sum()\n",
    "\n",
    "        if channel_weights:\n",
    "            wp_regions = wp_regions * C[:, None]\n",
    "        wp_regions /= np.linalg.norm(wp_regions, axis=0)\n",
    "\n",
    "        if max_pool:\n",
    "            if channel_weights:\n",
    "                mp_regions = mp_regions * C[:, None]\n",
    "            mp_regions /= np.linalg.norm(mp_regions, axis=0)\n",
    "\n",
    "        wsp_descriptors_reg[num_classes*i:num_classes*(i+1)] = np.transpose(wp_regions)\n",
    "\n",
    "        if max_pool:\n",
    "            wmp_descriptors_reg[num_classes*i:num_classes*(i+1)] = np.transpose(mp_regions)\n",
    "\n",
    "    #print 'Time elapsed computing image representations for the batch: ', time.time() - t\n",
    "\n",
    "    if max_pool:\n",
    "        return wsp_descriptors_reg, wmp_descriptors_reg\n",
    "    else:\n",
    "        return wsp_descriptors_reg\n",
    "    \n",
    "# General Descriptor Aggregation : PCA + Aggregation\n",
    "def descriptor_aggregation(descriptors_cams, num_images, num_classes, pca=None):\n",
    "\n",
    "    num_classes_ori = int(descriptors_cams.shape[0] / num_images)\n",
    "    descriptors = np.zeros((num_images, descriptors_cams.shape[1]), dtype=np.float32)\n",
    "\n",
    "    if pca is not None:\n",
    "        # Sometimes we may have errors during re-ranking due to bounding box generation on places where CAM=0\n",
    "        try:\n",
    "            descriptors_pca = pca.transform(descriptors_cams)\n",
    "        except:\n",
    "            print ('---------------------------->Exception')\n",
    "            desc_err = np.zeros((descriptors_cams.shape[0], descriptors_cams.shape[1]), dtype=np.float32)\n",
    "            for j in range(0, descriptors_cams.shape[0]):\n",
    "                try:\n",
    "                    desc_err[j] = pca.transform(descriptors_cams[j])\n",
    "                except:\n",
    "                    print ('---------------------------->Exception')\n",
    "                    print (j)\n",
    "                    desc_err[j] = desc_err[j-1]\n",
    "            descriptors_pca = desc_err\n",
    "\n",
    "        descriptors = np.zeros((num_images, descriptors_pca.shape[1]), dtype=np.float32)\n",
    "        #print descriptors_pca.shape\n",
    "\n",
    "    index = 0\n",
    "    for i in range(0, num_images):\n",
    "        index = num_classes_ori + index\n",
    "        if i == 0:\n",
    "            index = 0\n",
    "        if pca is not None:\n",
    "            for k in range(index, index+num_classes):\n",
    "                descriptors_pca[k] /= np.linalg.norm(descriptors_pca[k])\n",
    "                descriptors[i] += descriptors_pca[k]\n",
    "\n",
    "            descriptors[i] /= np.linalg.norm(descriptors[i])\n",
    "        else:\n",
    "            for k in range(index, index+num_classes):\n",
    "                descriptors[i] += descriptors_cams[k]\n",
    "            descriptors[i] /= np.linalg.norm(descriptors[i])\n",
    "\n",
    "    return descriptors\n",
    "\n",
    "#load model and transfer to GPU\n",
    "device = torch.device(\"cuda\")\n",
    "best_net = resnet50(num_classes=2)\n",
    "best_net.load_state_dict(torch.load( '/data/tmpexec/CAM.pkl'))\n",
    "best_net.to(device)\n",
    "\n",
    "weights_fc = best_net.fc.state_dict()['weight'] #tensor([2, 2048])\n",
    "weights_fc = np.transpose(weights_fc.cpu().numpy(), (1, 0)) #numpy(2048, 2)\n",
    "#extract feature-cam for trainset\n",
    "batchSize=10\n",
    "num_samples = len(trI)\n",
    "n_classes = 2\n",
    "class_list = np.zeros((num_samples, n_classes), dtype=np.int32)\n",
    "scores_vec = list()\n",
    "# Region of interest for re-ranking (bounding box coordinates --> (num samples, num_thresholds, x,y,dx,dy)\n",
    "bbox_coord = np.zeros((num_samples, 5, 4), dtype=np.int16)\n",
    "num_batches = len(trI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    conv_outputs_cam, scores = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    conv_outputs_cam = conv_outputs_cam.data.cpu().numpy()\n",
    "    scores = scores.data.cpu().numpy()\n",
    "    if i == 0:\n",
    "        features_conv = np.zeros((num_samples, conv_outputs_cam.shape[1], conv_outputs_cam.shape[2], conv_outputs_cam.shape[3]))\n",
    "        cams = np.zeros((num_samples, n_classes, conv_outputs_cam.shape[2], conv_outputs_cam.shape[3]))\n",
    "        features_conv[min_idx:max_idx, :, :, :] = conv_outputs_cam\n",
    "    else:\n",
    "        features_conv[min_idx:max_idx, :, :, :] = conv_outputs_cam\n",
    "    \n",
    "    for ii in range(0, max_idx-min_idx):\n",
    "        indexed_scores = scores[ii].argsort()[::-1]\n",
    "        scores_vec.append(scores[ii])\n",
    "        for k in range(0, n_classes):\n",
    "            w_class = weights_fc[:, indexed_scores[k]]\n",
    "            cam = np.zeros(dtype=np.float32, shape=conv_outputs_cam.shape[2:4])\n",
    "            for ind, w in enumerate(w_class):\n",
    "                cam += w * conv_outputs_cam[ii, ind, :, :]\n",
    "            cam /= np.max(cam)\n",
    "            cam[np.where(cam < 0)] = 0\n",
    "            cams[min_idx+ii, k, :, :] = cam\n",
    "            class_list[min_idx+ii, k] = indexed_scores[k]\n",
    "            \n",
    "        heatmap = cams[min_idx+ii, 0]\n",
    "        bbox_coord[min_idx+ii, 0, :] = extract_ROI(heatmap=heatmap, threshold=0.01)# Full Image\n",
    "        bbox_coord[min_idx+ii, 1, :] = extract_ROI(heatmap=heatmap, threshold=0.1)\n",
    "        bbox_coord[min_idx+ii, 2, :] = extract_ROI(heatmap=heatmap, threshold=0.2)\n",
    "        bbox_coord[min_idx+ii, 3, :] = extract_ROI(heatmap=heatmap, threshold=0.3)\n",
    "        bbox_coord[min_idx+ii, 4, :] = extract_ROI(heatmap=heatmap, threshold=0.4)\n",
    "#output: features_conv, cams, class_list, scores_vec, bbox_coord\n",
    "#extract features    \n",
    "d_wp = weighted_cam_pooling(features_conv, cams)\n",
    "#d_sp = sum_pooling(features_conv)\n",
    "# Compute Query Descriptor\n",
    "trF = descriptor_aggregation(d_wp, num_samples, n_classes)\n",
    "trF_pca = compute_pca(trF)\n",
    "\n",
    "#extract feature-cam for testset\n",
    "batchSize=10\n",
    "num_samples = len(teI)\n",
    "n_classes = 2\n",
    "class_list = np.zeros((num_samples, n_classes), dtype=np.int32)\n",
    "scores_vec = list()\n",
    "# Region of interest for re-ranking (bounding box coordinates --> (num samples, num_thresholds, x,y,dx,dy)\n",
    "bbox_coord = np.zeros((num_samples, 5, 4), dtype=np.int16)\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    conv_outputs_cam, scores = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    conv_outputs_cam = conv_outputs_cam.data.cpu().numpy()\n",
    "    scores = scores.data.cpu().numpy()\n",
    "    if i == 0:\n",
    "        features_conv = np.zeros((num_samples, conv_outputs_cam.shape[1], conv_outputs_cam.shape[2], conv_outputs_cam.shape[3]))\n",
    "        cams = np.zeros((num_samples, n_classes, conv_outputs_cam.shape[2], conv_outputs_cam.shape[3]))\n",
    "        features_conv[min_idx:max_idx, :, :, :] = conv_outputs_cam\n",
    "    else:\n",
    "        features_conv[min_idx:max_idx, :, :, :] = conv_outputs_cam\n",
    "    \n",
    "    for ii in range(0, max_idx-min_idx):\n",
    "        indexed_scores = scores[ii].argsort()[::-1]\n",
    "        scores_vec.append(scores[ii])\n",
    "        for k in range(0, n_classes):\n",
    "            w_class = weights_fc[:, indexed_scores[k]]\n",
    "            cam = np.zeros(dtype=np.float32, shape=conv_outputs_cam.shape[2:4])\n",
    "            for ind, w in enumerate(w_class):\n",
    "                cam += w * conv_outputs_cam[ii, ind, :, :]\n",
    "            cam /= np.max(cam)\n",
    "            cam[np.where(cam < 0)] = 0\n",
    "            cams[min_idx+ii, k, :, :] = cam\n",
    "            class_list[min_idx+ii, k] = indexed_scores[k]\n",
    "            \n",
    "        heatmap = cams[min_idx+ii, 0]\n",
    "        bbox_coord[min_idx+ii, 0, :] = extract_ROI(heatmap=heatmap, threshold=0.01)# Full Image\n",
    "        bbox_coord[min_idx+ii, 1, :] = extract_ROI(heatmap=heatmap, threshold=0.1)\n",
    "        bbox_coord[min_idx+ii, 2, :] = extract_ROI(heatmap=heatmap, threshold=0.2)\n",
    "        bbox_coord[min_idx+ii, 3, :] = extract_ROI(heatmap=heatmap, threshold=0.3)\n",
    "        bbox_coord[min_idx+ii, 4, :] = extract_ROI(heatmap=heatmap, threshold=0.4)\n",
    "#output: features_conv, cams, class_list, scores_vec, bbox_coord\n",
    "#extract features    \n",
    "d_wp = weighted_cam_pooling(features_conv, cams)\n",
    "#d_sp = sum_pooling(features_conv)\n",
    "# Compute Query Descriptor\n",
    "teF = descriptor_aggregation(d_wp, num_samples, n_classes)\n",
    "#teF_pca = compute_pca(teF)\n",
    "\n",
    "#compute the size of lesion\n",
    "def Func_IOU_size(pred,target,n_classes = 3 ):\n",
    "    ious = []\n",
    "    # ignore IOU for background class\n",
    "    for cls in range(1,n_classes):\n",
    "        pred_inds = pred == cls\n",
    "        pred_sum = pred_inds.sum()\n",
    "        target_inds = target == cls\n",
    "        target_sum = target_inds.sum()\n",
    "        ious.append(round(float(min(pred_sum,target_sum)/max(pred_sum,target_sum)),4))\n",
    "    return np.mean(ious)\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(2048) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [5, 10, 20, 50]:\n",
    "    mAP = [] #mean average precision\n",
    "    mIoU = []\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "            mIoU.append(Func_IOU_size(teM[i],trM[j],n_classes=3))\n",
    "    print(\"mAP={:.4f}, mIoU={:.4f}\".format(np.mean(mAP),np.mean(mIoU)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = best_net.cpu()\n",
    "x_batch = x_batch.cpu()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--------below is the dataset split code and image show code--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    482\n",
      "True     168\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    433\n",
      "True     152\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    49\n",
      "True     16\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "datas = pd.read_csv(root_dir+\"labels.csv\" , sep=',')\n",
    "datas = datas[['filename','diagnosis(glaucoma=True)']]\n",
    "print(datas['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData, teData = train_test_split(datas, test_size=0.1) #split trainset and testset\n",
    "print(trData['diagnosis(glaucoma=True)'].value_counts())\n",
    "print(teData['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/trainset.csv',index=False)\n",
    "teData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/testset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
