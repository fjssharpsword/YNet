{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from typing import Dict, List\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize,normalize\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage import zoom\n",
    "from functools import reduce\n",
    "from scipy.io import loadmat\n",
    "from skimage.measure import block_reduce\n",
    "from collections import Counter\n",
    "from scipy.sparse import coo_matrix,hstack, vstack\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.ops as ops\n",
    "torch.cuda.set_device(7)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3279 / 3279 The length of trainset is 3279\n",
      "365 / 365 The length of testset is 365\n",
      "Completed data handle in 108 seconds\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "root_dir = '/data/fjsdata/MCBIR-Ins/TNSCUI2020_train/' #the path of images\n",
    "trData = pd.read_csv(root_dir+\"trainset.csv\" , sep=',')\n",
    "teData = pd.read_csv(root_dir+\"testset.csv\" , sep=',')\n",
    "#trainset \n",
    "trN, trI, trM, trY = [],[],[],[]\n",
    "for iname, itype in np.array(trData).tolist():\n",
    "    try:\n",
    "        trN.append(iname)\n",
    "        trY.append(itype) #0 refer to Benign, and 1 refers to malignant\n",
    "        image_path = os.path.join(root_dir, 'image', iname)\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        trI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname)\n",
    "        mask = cv2.resize(cv2.imread(mask_path,0).astype(np.float32), (256, 256))/255#(256,256)\n",
    "        trM.append(np.where(mask == 0.0, 0, 1)) #0, 1\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "#testset\n",
    "teN, teI, teM, teY = [],[],[],[]\n",
    "for iname, itype in np.array(teData).tolist():\n",
    "    try:\n",
    "        teN.append(iname)\n",
    "        teY.append(itype) #0 refer to Benign, and 1 refers to malignant\n",
    "        image_path = os.path.join(root_dir, 'image', iname)\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        teI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname)\n",
    "        mask = cv2.resize(cv2.imread(mask_path,0).astype(np.float32), (256, 256))/255#(256,256)\n",
    "        teM.append(np.where(mask == 0.0, 0, 1))\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 163 / 163 : loss = 4.7789246Eopch:     1 mean_loss = 6.019000\n",
      " 163 / 163 : loss = 4.482318Eopch:     2 mean_loss = 4.638779\n",
      " 163 / 163 : loss = 3.288033Eopch:     3 mean_loss = 4.534117\n",
      " 163 / 163 : loss = 3.874118Eopch:     4 mean_loss = 4.355706\n",
      " 163 / 163 : loss = 4.447536Eopch:     5 mean_loss = 4.449228\n",
      " 163 / 163 : loss = 4.559335Eopch:     6 mean_loss = 4.212490\n",
      " 163 / 163 : loss = 5.101129Eopch:     7 mean_loss = 4.327943\n",
      " 163 / 163 : loss = 4.466219Eopch:     8 mean_loss = 4.318305\n",
      " 163 / 163 : loss = 5.400898Eopch:     9 mean_loss = 4.170705\n",
      " 163 / 163 : loss = 2.547299Eopch:    10 mean_loss = 4.049528\n",
      "best_loss = 4.049528\n",
      " 36 / 37 8 Completed buliding index in 23 seconds\n",
      "mAP=0.5625, mIoU=0.4498\n",
      "mAP=0.5356, mIoU=0.4411\n",
      "mAP=0.5105, mIoU=0.4424\n",
      "mAP=0.4928, mIoU=0.4387\n"
     ]
    }
   ],
   "source": [
    "#Baseline: DRH-MICCAI2017《Hashing with Residual Networks for Image Retrieval》\n",
    "#https://github.com/dansuh17/deep-supervised-hashing\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            ResBlock(in_channels=3, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16, stride=2),\n",
    "        )\n",
    "        self.linear_input_size = 16*128*128\n",
    "        self.linear = nn.Linear(self.linear_input_size, num_classes)\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(-1, self.linear_input_size)\n",
    "        return self.linear(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class DRH(nn.Module):\n",
    "    def __init__(self, code_size: int):\n",
    "        super().__init__()\n",
    "        resnet = ResNet(num_classes=10)\n",
    "        resnet.linear = nn.Linear(in_features=resnet.linear_input_size, out_features=code_size)\n",
    "        self.net = resnet\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "class HashLossFunc(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(HashLossFunc, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss\n",
    "\n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs():\n",
    "    if (len(trY) % 2) == 0: spls = len(trY)\n",
    "    else:  spls = len(trY)-1\n",
    "    idx_sf = random.sample(range(0, spls),spls)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "\n",
    "#define model\n",
    "model = DRH(code_size=36).cuda()\n",
    "criterion  = HashLossFunc(margin=0.5).cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs()\n",
    "num_batches = len(trY_sf) // batchSize \n",
    "for epoch in range(10):#iteration\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs()\n",
    "    losses = []\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_sf), (i+1)*batchSize])\n",
    "        I1_batch = torch.from_numpy(trI1_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion = criterion.cpu()\n",
    "I1_batch = I1_batch.cpu()\n",
    "I2_batch = I2_batch.cpu()\n",
    "Y_batch = Y_batch.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize + 1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize+1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#evaluate\n",
    "#compute the size of lesion\n",
    "def Func_IOU_size(pred,target):\n",
    "    ious = []\n",
    "    # ignore IOU for background class\n",
    "    pred_inds = pred != 0\n",
    "    pred_sum = pred_inds.sum()\n",
    "    target_inds = target != 0\n",
    "    target_sum = target_inds.sum()\n",
    "    ious.append(round(float(min(pred_sum,target_sum)/max(pred_sum,target_sum)),4))\n",
    "    return np.mean(ious)\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [5, 10, 20, 50]:\n",
    "    mAP = [] #mean average precision\n",
    "    mIoU = []\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "            mIoU.append(Func_IOU_size(teM[i],trM[j]))\n",
    "    print(\"mAP={:.4f}, mIoU={:.4f}\".format(np.mean(mAP),np.mean(mIoU)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion = criterion.cpu()\n",
    "I1_batch = I1_batch.cpu()\n",
    "I2_batch = I2_batch.cpu()\n",
    "Y_batch = Y_batch.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos: 12-itype:1-dtype:1\n",
      "pos: 12-itype:1-dtype:1\n",
      "pos: 12-itype:1-dtype:1\n",
      "pos: 12-itype:1-dtype:1\n",
      "pos: 12-itype:1-dtype:1\n",
      "pos: 12-itype:1-dtype:0\n",
      "['4385.PNG', '9037.PNG', '3519.PNG', '4183.PNG', '2272.PNG', '1331.PNG']\n"
     ]
    }
   ],
   "source": [
    "image_path_top = []\n",
    "for i in [12]:#range(len(trY)):\n",
    "    itype = trY[i]\n",
    "    teVal = trF[i]\n",
    "    image_path = os.path.join(root_dir, 'images', trN[i])\n",
    "    map_item_score = {}\n",
    "    scores, neighbors = gpu_index.search(np.array(trF[i:i+1]).astype('float32'), k=6)\n",
    "    for j in neighbors[0].tolist():\n",
    "        print ('pos: %d-itype:%d-dtype:%d'%(i,trY[i],trY[j]))\n",
    "        image_path_top.append(trN[j])\n",
    "print(image_path_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 62052, 1: 3484})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f569c392850>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_path= '/data/fjsdata/MCBIR-Ins/TNSCUI2020_train/mask/1331.PNG'\n",
    "mask = cv2.resize(cv2.imread(mask_path,0).astype(np.float32), (256, 256))/255\n",
    "mask = np.where(mask == 0.0, 0, 1)\n",
    "print(Counter(mask.flatten()))\n",
    "plt.title('Benign Size=3484' )#refer to Benign, and 1 refers to Malignant\n",
    "plt.axis('off')\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
