{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from typing import Dict, List\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "from functools import reduce\n",
    "from scipy.io import loadmat\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.set_device(3)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3279 / 3279 The length of trainset is 3279\n",
      "365 / 365 The length of testset is 365\n",
      "Completed data handle in 91 seconds\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "root_dir = '/data/fjsdata/MCBIR-Ins/TNSCUI2020_train/' #the path of images\n",
    "trData = pd.read_csv(root_dir+\"trainset.csv\" , sep=',')\n",
    "teData = pd.read_csv(root_dir+\"testset.csv\" , sep=',')\n",
    "#trainset \n",
    "trN, trI, trM, trY = [],[],[],[]\n",
    "for iname, itype in np.array(trData).tolist():\n",
    "    try:\n",
    "        trN.append(iname)\n",
    "        trY.append(itype) #0 refer to Benign, and 1 refers to malignant\n",
    "        image_path = os.path.join(root_dir, 'image', iname)\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        trI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname)\n",
    "        mask = cv2.resize(cv2.imread(mask_path,0).astype(np.float32), (256, 256))/255#(256,256)\n",
    "        trM.append(np.where(mask == 0.0, 0, 1)) #0, 1\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "#testset\n",
    "teN, teI, teM, teY = [],[],[],[]\n",
    "for iname, itype in np.array(teData).tolist():\n",
    "    try:\n",
    "        teN.append(iname)\n",
    "        teY.append(itype) #0 refer to Benign, and 1 refers to malignant\n",
    "        image_path = os.path.join(root_dir, 'image', iname)\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        teI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname)\n",
    "        mask = cv2.resize(cv2.imread(mask_path,0).astype(np.float32), (256, 256))/255#(256,256)\n",
    "        teM.append(np.where(mask == 0.0, 0, 1))\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes=2, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfgs = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "def vgg11(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") from\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['A'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg11_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['A'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['B'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['B'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['D'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['D'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration \"E\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['E'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['E'], batch_norm=True), **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 328 / 328 : loss = 0.778353Eopch:     1 mean_loss = 2.119906\n",
      " 328 / 328 : loss = 0.724028Eopch:     2 mean_loss = 0.695013\n",
      " 328 / 328 : loss = 0.874954Eopch:     3 mean_loss = 0.697721\n",
      " 328 / 328 : loss = 0.708334Eopch:     4 mean_loss = 0.691593\n",
      " 328 / 328 : loss = 0.707175Eopch:     5 mean_loss = 0.694588\n",
      " 328 / 328 : loss = 0.710558Eopch:     6 mean_loss = 0.689210\n",
      " 328 / 328 : loss = 0.679119Eopch:     7 mean_loss = 0.688130\n",
      " 328 / 328 : loss = 0.731568Eopch:     8 mean_loss = 0.688545\n",
      " 328 / 328 : loss = 0.666374Eopch:     9 mean_loss = 0.687878\n",
      " 328 / 328 : loss = 0.651518Eopch:    10 mean_loss = 0.688256\n",
      "best_loss = 0.687878\n",
      " 36 / 37 Sensitivity(TPR) of Benign: 0.000000\n",
      "Sensitivity(TPR) of Malignant: 1.000000\n",
      "AUC (Area Under Curve) of Micro: 0.473521\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define model\n",
    "model = vgg16_bn().cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define cross-entropy loss\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trI)))\n",
    "    trI_batch = np.array(trI)[shuffled_idx]\n",
    "    trY_batch = np.array(trY)[shuffled_idx]\n",
    "    num_batches = len(trI) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(trI_batch[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_batch[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        Out_batch = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = ce_loss(Out_batch,Y_batch)#loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()#update parameters\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#test model\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    prob = out_batch.max(1,keepdim=True)[0]\n",
    "    teY_prob.extend(prob.cpu().data.numpy().tolist())\n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().flatten().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#TNR= TN / (FP+TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR= TP / (TP+FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC curves: y axis:Sensitivity, x axis:1-Specificity\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print ('Sensitivity(TPR) of Benign: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of Malignant: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "#plot roc curve\n",
    "fpr_tce, tpr_tce, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) \n",
    "#plt.plot(fpr_ce, tpr_ce, c = 'r', ls = '--', label = u'ATH(our) AUC=%.4f' % auc_score)\n",
    "plt.plot(fpr_tce, tpr_tce, c = 'b', ls = '--', label = u'R-MAC AUC=%.4f' % auc_score) \n",
    "plt.plot((0, 1), (0, 1), c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.2))\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.grid(b=True, ls=':')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('TNSCUI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory and save model in CPU\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "best_net = best_net.cpu()\n",
    "torch.cuda.empty_cache() \n",
    "torch.save(best_net.state_dict(), '/data/tmpexec/R_MAC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Code: https://github.com/PyRetri/PyRetri\n",
    "       https://github.com/almazan/deep-image-retrieval\n",
    "       https://github.com/noagarcia/keras_rmac\n",
    "#Paper: ICLR2016《Particular object retrieval with integral max-pooling of CNN activations》\n",
    "        IJCV2017《End-to-end Learning of Deep Visual Representations for Image Retrieval》\n",
    "'''\n",
    "class RMAC():\n",
    "    \"\"\"\n",
    "    Regional Maximum activation of convolutions (R-MAC).\n",
    "    c.f. https://arxiv.org/pdf/1511.05879.pdf\n",
    "    Args:\n",
    "        level_n (int): number of levels for selecting regions.\n",
    "    \"\"\"\n",
    "    def __init__(self,level_n:int):\n",
    "        super(RMAC, self).__init__()\n",
    "        self.first_show = True\n",
    "        self.cached_regions = dict()\n",
    "        self.level_n = level_n\n",
    "\n",
    "    def _get_regions(self, h: int, w: int) -> List:\n",
    "        \"\"\"\n",
    "        Divide the image into several regions.\n",
    "        Args:\n",
    "            h (int): height for dividing regions.\n",
    "            w (int): width for dividing regions.\n",
    "        Returns:\n",
    "            regions (List): a list of region positions.\n",
    "        \"\"\"\n",
    "        if (h, w) in self.cached_regions:\n",
    "            return self.cached_regions[(h, w)]\n",
    "\n",
    "        m = 1\n",
    "        n_h, n_w = 1, 1\n",
    "        regions = list()\n",
    "        if h != w:\n",
    "            min_edge = min(h, w)\n",
    "            left_space = max(h, w) - min(h, w)\n",
    "            iou_target = 0.4\n",
    "            iou_best = 1.0\n",
    "            while True:\n",
    "                iou_tmp = (min_edge ** 2 - min_edge * (left_space // m)) / (min_edge ** 2)\n",
    "\n",
    "                # small m maybe result in non-overlap\n",
    "                if iou_tmp <= 0:\n",
    "                    m += 1\n",
    "                    continue\n",
    "\n",
    "                if abs(iou_tmp - iou_target) <= iou_best:\n",
    "                    iou_best = abs(iou_tmp - iou_target)\n",
    "                    m += 1\n",
    "                else:\n",
    "                    break\n",
    "            if h < w:\n",
    "                n_w = m\n",
    "            else:\n",
    "                n_h = m\n",
    "\n",
    "        for i in range(self.level_n):\n",
    "            region_width = int(2 * 1.0 / (i + 2) * min(h, w))\n",
    "            step_size_h = (h - region_width) // n_h\n",
    "            step_size_w = (w - region_width) // n_w\n",
    "\n",
    "            for x in range(n_h):\n",
    "                for y in range(n_w):\n",
    "                    st_x = step_size_h * x\n",
    "                    ed_x = st_x + region_width - 1\n",
    "                    assert ed_x < h\n",
    "                    st_y = step_size_w * y\n",
    "                    ed_y = st_y + region_width - 1\n",
    "                    assert ed_y < w\n",
    "                    regions.append((st_x, st_y, ed_x, ed_y))\n",
    "\n",
    "            n_h += 1\n",
    "            n_w += 1\n",
    "\n",
    "        self.cached_regions[(h, w)] = regions\n",
    "        return regions\n",
    "\n",
    "    def __call__(self, fea:torch.tensor) -> torch.tensor:\n",
    "        final_fea = None\n",
    "        if fea.ndimension() == 4:\n",
    "            h, w = fea.shape[2:]       \n",
    "            regions = self._get_regions(h, w)\n",
    "            for _, r in enumerate(regions):\n",
    "                st_x, st_y, ed_x, ed_y = r\n",
    "                region_fea = (fea[:, :, st_x: ed_x, st_y: ed_y].max(dim=3)[0]).max(dim=2)[0]\n",
    "                region_fea = region_fea / torch.norm(region_fea, dim=1, keepdim=True)\n",
    "                if final_fea is None:\n",
    "                    final_fea = region_fea\n",
    "                else:\n",
    "                    final_fea = final_fea + region_fea\n",
    "        else:# In case of fc feature.\n",
    "            assert fea.ndimension() == 2\n",
    "            if self.first_show:\n",
    "                print(\"[RMAC Aggregator]: find 2-dimension feature map, skip aggregation\")\n",
    "                self.first_show = False\n",
    "            final_fea = fea\n",
    "        return final_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed buliding index in 24 seconds\n",
      "mAP=0.3701, mIoU=0.3866\n",
      "mAP=0.3294, mIoU=0.3792\n",
      "mAP=0.3063, mIoU=0.3760\n",
      "mAP=0.2860, mIoU=0.3767\n"
     ]
    }
   ],
   "source": [
    "#load model and transfer to GPU\n",
    "device = torch.device(\"cuda\")\n",
    "best_net = vgg16_bn()\n",
    "best_net.load_state_dict(torch.load( '/data/tmpexec/R_MAC.pkl'))\n",
    "best_net.to(device)\n",
    "#1. Extract features based on backbone and Aggregate R-MAC\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "best_net.features.register_forward_hook(get_activation('features'))\n",
    "\n",
    "batchSize=10\n",
    "rmac = RMAC(level_n=3)\n",
    "trF = []\n",
    "num_batches = len(trI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    feat_batch = activation['features'].squeeze()\n",
    "    feat_ret_batch = rmac(feat_batch)\n",
    "    trF.extend(feat_ret_batch.cpu().numpy().tolist())\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    feat_batch = activation['features'].squeeze()\n",
    "    feat_ret_batch = rmac(feat_batch)\n",
    "    teF.extend(feat_ret_batch.cpu().numpy().tolist())\n",
    "\n",
    "#compute the size of lesion\n",
    "#compute the size of lesion\n",
    "def Func_IOU_size(pred,target):\n",
    "    ious = []\n",
    "    # ignore IOU for background class\n",
    "    pred_inds = pred != 0\n",
    "    pred_sum = pred_inds.sum()\n",
    "    target_inds = target != 0\n",
    "    target_sum = target_inds.sum()\n",
    "    ious.append(round(float(min(pred_sum,target_sum)/max(pred_sum,target_sum)),4))\n",
    "    return np.mean(ious)\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(512) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [5, 10, 20, 50]:\n",
    "    mAP = [] #mean average precision\n",
    "    mIoU = []\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "            mIoU.append(Func_IOU_size(teM[i],trM[j]))\n",
    "    print(\"mAP={:.4f}, mIoU={:.4f}\".format(np.mean(mAP),np.mean(mIoU)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--------below is the dataset split code and image show code--------------------------------------\n",
    "#https://github.com/escorciav/roi_pooling\n",
    "#https://github.com/kuangliu/pytorch-roipooling/blob/master/test_roipooling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.4319, mIoU=0.4070\n"
     ]
    }
   ],
   "source": [
    "#compute the size of lesion\n",
    "def Func_IOU_size(pred,target):\n",
    "    ious = []\n",
    "    # ignore IOU for background class\n",
    "    pred_inds = pred != 0\n",
    "    pred_sum = pred_inds.sum()\n",
    "    target_inds = target != 0\n",
    "    target_sum = target_inds.sum()\n",
    "    ious.append(round(float(min(pred_sum,target_sum)/max(pred_sum,target_sum)),4))\n",
    "    return np.mean(ious)\n",
    "for topk in [10]:\n",
    "    mAP = [] #mean average precision\n",
    "    mIoU = []\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "            mIoU.append(Func_IOU_size(teM[i],trM[j]))\n",
    "    print(\"mAP={:.4f}, mIoU={:.4f}\".format(np.mean(mAP),np.mean(mIoU)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 192576, 255.0: 3852, 251.01562: 18, 107.578125: 15, 195.23438: 6, 3.984375: 6, 41.88263: 3, 116.54297: 3, 127.359924: 3, 119.17328: 3, 92.27875: 3, 5.649719: 3, 198.26935: 3, 227.10938: 3, 250.01953: 3, 252.2763: 3, 36.964417: 3, 124.51172: 3, 254.76654: 3, 123.03314: 3, 22.77008: 3, 43.828125: 3, 251.12457: 3, 156.83807: 3, 106.286316: 3, 203.20312: 3, 3.8442993: 3, 170.06744: 3, 128.79181: 3, 155.39062: 3, 246.82892: 3, 69.39972: 3, 76.24786: 3, 243.04688: 3, 1.1050415: 3, 107.31354: 3, 181.46027: 3, 117.14996: 3, 51.796875: 3, 240.63446: 3, 43.65692: 3, 209.4754: 3, 147.42188: 3, 198.64288: 3, 187.26562: 3, 204.3393: 3, 153.44513: 3, 237.17926: 3, 3.7820435: 3, 186.0672: 3, 22.910156: 3})\n",
      "4032\n",
      "192576\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(np.array(trM[0]).flatten()))\n",
    "pred_inds = trM[0]!= 0\n",
    "pred_sum = pred_inds.sum()\n",
    "print (pred_sum)\n",
    "pred_inds = trM[0]== 0\n",
    "pred_sum = pred_inds.sum()\n",
    "print (pred_sum)\n",
    "imgplot = plt.imshow(trM[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2003\n",
      "0    1641\n",
      "Name: CATE, dtype: int64\n",
      "1    1810\n",
      "0    1469\n",
      "Name: CATE, dtype: int64\n",
      "1    193\n",
      "0    172\n",
      "Name: CATE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "datas = pd.read_csv(\"/data/fjsdata/MCBIR-Ins/TNSCUI2020_train/train.csv\" , sep=',')\n",
    "datas = datas[['ID','CATE']]\n",
    "print(datas['CATE'].value_counts())\n",
    "trData, teData = train_test_split(datas, test_size=0.1) #split trainset and testset\n",
    "print(trData['CATE'].value_counts())\n",
    "print(teData['CATE'].value_counts())\n",
    "trData.to_csv( '/data/fjsdata/MCBIR-Ins/TNSCUI2020_train/trainset.csv',index=False)\n",
    "teData.to_csv( '/data/fjsdata/MCBIR-Ins/TNSCUI2020_train/testset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
