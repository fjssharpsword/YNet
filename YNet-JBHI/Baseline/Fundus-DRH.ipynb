{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from typing import Dict, List\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize,normalize\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage import zoom\n",
    "from functools import reduce\n",
    "from scipy.io import loadmat\n",
    "from skimage.measure import block_reduce\n",
    "from collections import Counter\n",
    "from scipy.sparse import coo_matrix,hstack, vstack\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.ops as ops\n",
    "torch.cuda.set_device(7)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585 / 585 The length of trainset is 585\n",
      "65 / 65 The length of testset is 65\n",
      "Completed data handle in 103 seconds\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "root_dir = '/data/fjsdata/MCBIR-Ins/origa650/' #the path of images\n",
    "trData = pd.read_csv(root_dir+\"trainset.csv\" , sep=',')\n",
    "teData = pd.read_csv(root_dir+\"testset.csv\" , sep=',')\n",
    "#trainset \n",
    "trN, trI, trM, trY = [],[],[],[]\n",
    "for iname, itype in np.array(trData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        trN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            trY.append(1)\n",
    "        else: trY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        trI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        trM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "#testset\n",
    "teN, teI, teM, teY = [],[],[],[]\n",
    "for iname, itype in np.array(teData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        teN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            teY.append(1)\n",
    "        else: teY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        teI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        teM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29 / 29 : loss = 6.9853913Eopch:     1 mean_loss = 12.836882\n",
      " 29 / 29 : loss = 4.488482Eopch:     2 mean_loss = 5.396898\n",
      " 29 / 29 : loss = 5.806445Eopch:     3 mean_loss = 4.641309\n",
      " 29 / 29 : loss = 3.442748Eopch:     4 mean_loss = 4.103210\n",
      " 29 / 29 : loss = 4.217492Eopch:     5 mean_loss = 4.618119\n",
      " 29 / 29 : loss = 2.934872Eopch:     6 mean_loss = 4.077280\n",
      " 29 / 29 : loss = 3.347312Eopch:     7 mean_loss = 3.807517\n",
      " 29 / 29 : loss = 4.742602Eopch:     8 mean_loss = 4.196169\n",
      " 29 / 29 : loss = 4.357125Eopch:     9 mean_loss = 3.841332\n",
      " 29 / 29 : loss = 4.768262Eopch:    10 mean_loss = 3.668660\n",
      "best_loss = 3.668660\n",
      " 6 / 7 9 Completed buliding index in 24 seconds\n",
      "mAP=0.6468, mIoU=0.7239\n",
      "mAP=0.6124, mIoU=0.7218\n",
      "mAP=0.5805, mIoU=0.7198\n",
      "mAP=0.5538, mIoU=0.7191\n"
     ]
    }
   ],
   "source": [
    "#Baseline: DRH-MICCAI2017《Hashing with Residual Networks for Image Retrieval》\n",
    "#https://github.com/dansuh17/deep-supervised-hashing\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            ResBlock(in_channels=3, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16, stride=2),\n",
    "        )\n",
    "        self.linear_input_size = 16*128*128\n",
    "        self.linear = nn.Linear(self.linear_input_size, num_classes)\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(-1, self.linear_input_size)\n",
    "        return self.linear(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class DRH(nn.Module):\n",
    "    def __init__(self, code_size: int):\n",
    "        super().__init__()\n",
    "        resnet = ResNet(num_classes=10)\n",
    "        resnet.linear = nn.Linear(in_features=resnet.linear_input_size, out_features=code_size)\n",
    "        self.net = resnet\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "class HashLossFunc(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(HashLossFunc, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss\n",
    "\n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs():\n",
    "    if (len(trY) % 2) == 0: spls = len(trY)\n",
    "    else:  spls = len(trY)-1\n",
    "    idx_sf = random.sample(range(0, spls),spls)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "\n",
    "#define model\n",
    "model = DRH(code_size=36).cuda()\n",
    "criterion  = HashLossFunc(margin=0.5).cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs()\n",
    "num_batches = len(trY_sf) // batchSize \n",
    "for epoch in range(10):#iteration\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs()\n",
    "    losses = []\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_sf), (i+1)*batchSize])\n",
    "        I1_batch = torch.from_numpy(trI1_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion = criterion.cpu()\n",
    "I1_batch = I1_batch.cpu()\n",
    "I2_batch = I2_batch.cpu()\n",
    "Y_batch = Y_batch.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize + 1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize+1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#evaluate\n",
    "#compute the size of lesion\n",
    "def Func_IOU_size(pred,target,n_classes = 3 ):\n",
    "    ious = []\n",
    "    # ignore IOU for background class\n",
    "    for cls in range(1,n_classes):\n",
    "        pred_inds = pred == cls\n",
    "        pred_sum = pred_inds.sum()\n",
    "        target_inds = target == cls\n",
    "        target_sum = target_inds.sum()\n",
    "        ious.append(round(float(min(pred_sum,target_sum)/max(pred_sum,target_sum)),4))\n",
    "    return np.mean(ious)\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [5, 10, 20, 50]:\n",
    "    mAP = [] #mean average precision\n",
    "    mIoU = []\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "            mIoU.append(Func_IOU_size(teM[i],trM[j]))\n",
    "    print(\"mAP={:.4f}, mIoU={:.4f}\".format(np.mean(mAP),np.mean(mIoU)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion = criterion.cpu()\n",
    "I1_batch = I1_batch.cpu()\n",
    "I2_batch = I2_batch.cpu()\n",
    "Y_batch = Y_batch.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos: 39-itype:1-dtype:1\n",
      "pos: 39-itype:1-dtype:0\n",
      "pos: 39-itype:1-dtype:0\n",
      "pos: 39-itype:1-dtype:1\n",
      "pos: 39-itype:1-dtype:0\n",
      "pos: 39-itype:1-dtype:1\n",
      "['429', '403', '346', '270', '183', '228']\n"
     ]
    }
   ],
   "source": [
    "image_path_top = []\n",
    "for i in [39]:#[5, 10,15,31,39]:#range(len(trY)):\n",
    "    itype = trY[i]\n",
    "    teVal = trF[i]\n",
    "    image_path = os.path.join(root_dir, 'images', trN[i])\n",
    "    map_item_score = {}\n",
    "    scores, neighbors = gpu_index.search(np.array(trF[i:i+1]).astype('float32'), k=6)\n",
    "    for j in neighbors[0].tolist():\n",
    "        print ('pos: %d-itype:%d-dtype:%d'%(i,trY[i],trY[j]))\n",
    "        image_path_top.append(trN[j])\n",
    "print(image_path_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = loadmat('/data/fjsdata/MCBIR-Ins/origa650/mask/228.mat')['mask']\n",
    "mask = cv2.resize(mask,(256, 256))\n",
    "print (mask.shape)\n",
    "#print(Counter(mask.flatten()))\n",
    "imgplot = plt.imshow(mask)\n",
    "plt.title('Glaucoma CDR=0.5996' )#Glaucoma, Normal\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
