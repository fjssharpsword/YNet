{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from typing import Dict, List\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize,normalize\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage import zoom\n",
    "from functools import reduce\n",
    "from scipy.io import loadmat\n",
    "from skimage.measure import block_reduce\n",
    "from collections import Counter\n",
    "from scipy.sparse import coo_matrix,hstack, vstack\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.ops as ops\n",
    "torch.cuda.set_device(2)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3279 / 3279 The length of trainset is 3279\n",
      "365 / 365 The length of testset is 365\n",
      "Completed data handle in 90 seconds\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "root_dir = '/data/fjsdata/MCBIR-Ins/TNSCUI2020_train/' #the path of images\n",
    "trData = pd.read_csv(root_dir+\"trainset.csv\" , sep=',')\n",
    "teData = pd.read_csv(root_dir+\"testset.csv\" , sep=',')\n",
    "#trainset \n",
    "trN, trI, trM, trY = [],[],[],[]\n",
    "for iname, itype in np.array(trData).tolist():\n",
    "    try:\n",
    "        trN.append(iname)\n",
    "        trY.append(itype) #0 refer to Benign, and 1 refers to malignant\n",
    "        image_path = os.path.join(root_dir, 'image', iname)\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        trI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname)\n",
    "        mask = cv2.resize(cv2.imread(mask_path,0).astype(np.float32), (256, 256))/255#(256,256)\n",
    "        trM.append(np.where(mask == 0.0, 0, 1)) #0, 1\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "#testset\n",
    "teN, teI, teM, teY = [],[],[],[]\n",
    "for iname, itype in np.array(teData).tolist():\n",
    "    try:\n",
    "        teN.append(iname)\n",
    "        teY.append(itype) #0 refer to Benign, and 1 refers to malignant\n",
    "        image_path = os.path.join(root_dir, 'image', iname)\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        teI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname)\n",
    "        mask = cv2.resize(cv2.imread(mask_path,0).astype(np.float32), (256, 256))/255#(256,256)\n",
    "        teM.append(np.where(mask == 0.0, 0, 1))\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes=2, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfgs = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "def vgg11(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") from\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['A'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg11_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['A'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['B'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['B'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['D'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['D'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration \"E\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['E'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['E'], batch_norm=True), **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 328 / 328 : loss = 0.685085Eopch:     1 mean_loss = 2.405131\n",
      " 328 / 328 : loss = 0.670934Eopch:     2 mean_loss = 0.696450\n",
      " 328 / 328 : loss = 0.633427Eopch:     3 mean_loss = 0.690692\n",
      " 328 / 328 : loss = 0.713257Eopch:     4 mean_loss = 0.698147\n",
      " 328 / 328 : loss = 0.606869Eopch:     5 mean_loss = 0.704486\n",
      " 328 / 328 : loss = 0.734425Eopch:     6 mean_loss = 0.743421\n",
      " 328 / 328 : loss = 0.714712Eopch:     7 mean_loss = 0.690450\n",
      " 328 / 328 : loss = 0.661278Eopch:     8 mean_loss = 0.690970\n",
      " 328 / 328 : loss = 0.738402Eopch:     9 mean_loss = 0.688899\n",
      " 328 / 328 : loss = 0.718297Eopch:    10 mean_loss = 0.689622\n",
      "best_loss = 0.688899\n",
      " 36 / 37 Sensitivity(TPR) of Benign: 0.000000\n",
      "Sensitivity(TPR) of Malignant: 1.000000\n",
      "AUC (Area Under Curve) of Micro: 0.535275\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define model\n",
    "model = vgg16_bn().cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define cross-entropy loss\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trI)))\n",
    "    trI_batch = np.array(trI)[shuffled_idx]\n",
    "    trY_batch = np.array(trY)[shuffled_idx]\n",
    "    num_batches = len(trI) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(trI_batch[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_batch[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        Out_batch = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = ce_loss(Out_batch,Y_batch)#loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()#update parameters\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#test model\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    prob = out_batch.max(1,keepdim=True)[0]\n",
    "    teY_prob.extend(prob.cpu().data.numpy().tolist())\n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().flatten().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#TNR= TN / (FP+TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR= TP / (TP+FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC curves: y axis:Sensitivity, x axis:1-Specificity\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print ('Sensitivity(TPR) of Benign: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of Malignant: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "#plot roc curve\n",
    "fpr_tce, tpr_tce, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) \n",
    "#plt.plot(fpr_ce, tpr_ce, c = 'r', ls = '--', label = u'ATH(our) AUC=%.4f' % auc_score)\n",
    "plt.plot(fpr_tce, tpr_tce, c = 'b', ls = '--', label = u'R-MAC AUC=%.4f' % auc_score) \n",
    "plt.plot((0, 1), (0, 1), c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.2))\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.grid(b=True, ls=':')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('TNSCUI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory and save model in CPU\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "best_net = best_net.cpu()\n",
    "torch.cuda.empty_cache() \n",
    "torch.save(best_net.state_dict(), '/data/tmpexec/BLCF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing PCA-w...\n",
      "DONE! 5.23s\n",
      "Fitting vocabulary\n",
      "DONE! 2201.46s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Code: https://github.com/imatge-upc/salbow/tree/master/src/BLCF\n",
    "       https://github.com/imatge-upc/retrieval-2016-icmr\n",
    "#Paper: CBMI2018《Saliency Weighted Convolutional Features for Instance Search》\n",
    "        ICMR2016《Bags of local convolutional features for scalable instance search》\n",
    "'''\n",
    "\n",
    "#load model and transfer to GPU\n",
    "device = torch.device(\"cuda\")\n",
    "best_net = vgg16_bn()\n",
    "best_net.load_state_dict(torch.load( '/data/tmpexec/BLCF.pkl'))\n",
    "best_net.to(device)\n",
    "#1. Extract features based on backbone and Aggregate R-MAC\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "best_net.features.register_forward_hook(get_activation('features'))\n",
    "\n",
    "# get codebook\n",
    "def get_codebook(ConvFeat, n_clusters=1000, n_components=100):\n",
    "    \"\"\"\n",
    "    Compute PCA and codebook models\n",
    "    arg: n_clusters --  size of vocabulary\n",
    "         n_components -- dim PCA model / None if not computing PCA\n",
    "    \"\"\"\n",
    "    print (\"computing PCA-w...\")\n",
    "    training_feats  = []\n",
    "    for i in range(len(ConvFeat)):\n",
    "        feat = np.transpose( np.array(ConvFeat[i]), (1,2,0) )\n",
    "        r, c, ch = feat.shape\n",
    "        feat = np.reshape( feat, (r*c, -1) )\n",
    "        training_feats.extend(feat)\n",
    "    training_feats = np.array(training_feats)\n",
    "    training_feats = normalize(training_feats)\n",
    "    t0 = time.time()\n",
    "    pca_model = PCA(n_components, whiten=True)\n",
    "    pca_model.fit(training_feats)\n",
    "    t1 = time.time()\n",
    "    print (\"DONE! %.2fs\" % (t1-t0))\n",
    "\n",
    "    training_feats = pca_model.transform(training_feats)\n",
    "    print (\"Fitting vocabulary\")\n",
    "    t0 = time.time()\n",
    "    kmeans =KMeans(n_clusters=n_clusters, random_state=0).fit(training_feats)\n",
    "    t1 = time.time()\n",
    "    print (\"DONE! %.2fs\" % (t1-t0))\n",
    "\n",
    "    return pca_model, kmeans #kmeans.cluster_centers_\n",
    "\n",
    "batchSize=10\n",
    "trF = []\n",
    "num_batches = len(trI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    feat_batch = activation['features'].squeeze()\n",
    "    trF.extend(feat_batch.cpu().numpy().tolist())\n",
    "    \n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    feat_batch = activation['features'].squeeze()\n",
    "    teF.extend(feat_batch.cpu().numpy().tolist())\n",
    "    \n",
    "pca_model, kmeans = get_codebook(trF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = best_net.cpu()\n",
    "x_batch = x_batch.cpu()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3279, 1000)\n",
      "(365, 1000)\n",
      "Completed buliding index in 22 seconds\n",
      "mAP=0.3748, mIoU=0.3752\n",
      "mAP=0.3384, mIoU=0.3792\n",
      "mAP=0.3142, mIoU=0.3775\n",
      "mAP=0.2882, mIoU=0.3746\n"
     ]
    }
   ],
   "source": [
    "def get_bow( assignments, weights, n=1000):\n",
    "    '''\n",
    "    Funtion to build BoW representation given an assignment map.\n",
    "    args:\n",
    "        assignments - 2D map with assignments associated to each local feature\n",
    "        weights     - 2D maps with normalized (0-1) spatial weighting scheme\n",
    "        n           - size of the visual vocabulary (default 1000)\n",
    "    '''\n",
    "    # sparse encoding !\n",
    "    rows = np.array([], dtype=np.int)\n",
    "    cols = np.array([], dtype=np.int)\n",
    "    vals = np.array([], dtype=np.float)\n",
    "    n_docs = 0\n",
    "\n",
    "    # get counts\n",
    "    cnt = Counter(assignments.flatten())\n",
    "    ids = list(cnt.keys())#np.array(cnt.keys())\n",
    "    weights = weights.flatten()\n",
    "    weights = np.array([weights[np.where(assignments.flatten()==i)[0]].sum() for i in ids])\n",
    "\n",
    "    #save index\n",
    "    cols = np.append( cols, np.array(ids).astype(int) )\n",
    "    rows = np.append( rows, np.ones( len(cnt.keys()), dtype=int )*n_docs )\n",
    "    vals = np.append( vals, weights.astype(float) )\n",
    "    n_docs +=1\n",
    "\n",
    "    bow = coo_matrix( ( vals, (rows, cols) ), shape=(n_docs,n) )\n",
    "    bow = bow.tocsr()\n",
    "    #    bow = normalize(bow)\n",
    "    return bow\n",
    "#trainset\n",
    "for i in range(len(trF)):\n",
    "    feat = np.array(trF[i])\n",
    "    mask = np.array(trI[i])\n",
    "    #assignments maps\n",
    "    #feat = zoom(feat, (1,32,32), order=1) #interpolate=256/8=32\n",
    "    feat = np.reshape( feat, (feat.shape[0], -1) )\n",
    "    feat = np.transpose( feat, (1,0) )\n",
    "    feat = normalize(feat)\n",
    "    feat = pca_model.transform(feat)\n",
    "    feat = normalize(feat)\n",
    "    assigns = kmeans.predict(feat)\n",
    "    #Normalized saliency\n",
    "    mask = block_reduce( mask[:,:,0], (32,32), np.max )#downsample\n",
    "    mask = mask.astype(np.float32)\n",
    "    if not np.any(mask):\n",
    "        mask[...]=1\n",
    "    mask = mask / mask.max()\n",
    "    #get bags of words\n",
    "    bow = get_bow(assigns, mask)\n",
    "    if i == 0:\n",
    "        tr_bow = bow\n",
    "    else:\n",
    "        tr_bow = vstack( [tr_bow, bow] )\n",
    "tr_bow = normalize(tr_bow)\n",
    "print(tr_bow.shape)\n",
    "#testset\n",
    "for i in range(len(teF)):\n",
    "    feat = np.array(teF[i])\n",
    "    mask = np.array(teI[i])\n",
    "    #assignments maps\n",
    "    #feat = zoom(feat, (1,32,32), order=1) #interpolate=256/8=32\n",
    "    feat = np.reshape( feat, (feat.shape[0], -1) )\n",
    "    feat = np.transpose( feat, (1,0) )\n",
    "    feat = normalize(feat)\n",
    "    feat = pca_model.transform(feat)\n",
    "    feat = normalize(feat)\n",
    "    assigns = kmeans.predict(feat)\n",
    "    #Normalized saliency\n",
    "    mask = block_reduce( mask[:,:,0], (32,32), np.max )#downsample\n",
    "    mask = mask.astype(np.float32)\n",
    "    if not np.any(mask):\n",
    "        mask[...]=1\n",
    "    mask = mask / mask.max()\n",
    "    #get bags of words\n",
    "    bow = get_bow(assigns, mask)\n",
    "    if i == 0:\n",
    "        te_bow = bow\n",
    "    else:\n",
    "        te_bow = vstack( [te_bow, bow] )\n",
    "te_bow = normalize(te_bow)\n",
    "print(te_bow.shape)\n",
    "\n",
    "#evaluate\n",
    "#compute the size of lesion\n",
    "def Func_IOU_size(pred,target):\n",
    "    ious = []\n",
    "    # ignore IOU for background class\n",
    "    pred_inds = pred != 0\n",
    "    pred_sum = pred_inds.sum()\n",
    "    target_inds = target != 0\n",
    "    target_sum = target_inds.sum()\n",
    "    ious.append(round(float(min(pred_sum,target_sum)/max(pred_sum,target_sum)),4))\n",
    "    return np.mean(ious)\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(1000) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(tr_bow.toarray(), dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [5, 10, 20, 50]:\n",
    "    mAP = [] #mean average precision\n",
    "    mIoU = []\n",
    "    scores, neighbors = gpu_index.search(te_bow.toarray().astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(te_bow.toarray().tolist()):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "            mIoU.append(Func_IOU_size(teM[i],trM[j]))\n",
    "    print(\"mAP={:.4f}, mIoU={:.4f}\".format(np.mean(mAP),np.mean(mIoU)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--------below is the dataset split code and image show code--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    482\n",
      "True     168\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    433\n",
      "True     152\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    49\n",
      "True     16\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "datas = pd.read_csv(root_dir+\"labels.csv\" , sep=',')\n",
    "datas = datas[['filename','diagnosis(glaucoma=True)']]\n",
    "print(datas['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData, teData = train_test_split(datas, test_size=0.1) #split trainset and testset\n",
    "print(trData['diagnosis(glaucoma=True)'].value_counts())\n",
    "print(teData['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/trainset.csv',index=False)\n",
    "teData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/testset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
