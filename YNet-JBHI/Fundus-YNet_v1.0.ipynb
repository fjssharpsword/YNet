{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from typing import Dict, List\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize,normalize\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage import zoom\n",
    "from functools import reduce\n",
    "from scipy.io import loadmat\n",
    "from skimage.measure import block_reduce\n",
    "from collections import Counter\n",
    "from scipy.sparse import coo_matrix,hstack, vstack\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.ops as ops\n",
    "torch.cuda.set_device(0)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585 / 585 The length of trainset is 585\n",
      "65 / 65 The length of testset is 65\n",
      "Completed data handle in 104 seconds\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "root_dir = '/data/fjsdata/MCBIR-Ins/origa650/' #the path of images\n",
    "trData = pd.read_csv(root_dir+\"trainset.csv\" , sep=',')\n",
    "teData = pd.read_csv(root_dir+\"testset.csv\" , sep=',')\n",
    "#trainset \n",
    "trN, trI, trM, trY = [],[],[],[]\n",
    "for iname, itype in np.array(trData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        trN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            trY.append(1)\n",
    "        else: trY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        trI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        trM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "#testset\n",
    "teN, teI, teM, teY = [],[],[],[]\n",
    "for iname, itype in np.array(teData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        teN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            teY.append(1)\n",
    "        else: teY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        teI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        teM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "New loss for Y-Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Normalization(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we construct three nn.Linear instances that we will use\n",
    "        in the forward pass.\n",
    "        \"\"\"\n",
    "        super(L2Normalization, self).__init__()\n",
    "        self.eps = 1e-8\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.is_cuda:\n",
    "            caped_eps = Variable(torch.Tensor([self.eps])).cuda(torch.cuda.device_of(x).idx)\n",
    "        else:\n",
    "            caped_eps = Variable(torch.Tensor([self.eps]))\n",
    "        x = torch.div(x.transpose(0,1),x.max(1)[0]).transpose(0,1) # max_normed\n",
    "        norm = torch.norm(x,2,1) + caped_eps.expand(x.size()[0])\n",
    "        y = torch.div(x.transpose(0,1),norm).transpose(0,1)\n",
    "        return y\n",
    "    \n",
    "class RMAC(nn.Module):\n",
    "    \"\"\"\n",
    "    Regional Maximum activation of convolutions (R-MAC).\n",
    "    c.f. https://arxiv.org/pdf/1511.05879.pdf\n",
    "    Args:\n",
    "        level_n (int): number of levels for selecting regions.\n",
    "    \"\"\"\n",
    "    def __init__(self,level_n:int):\n",
    "        super(RMAC, self).__init__()\n",
    "        self.first_show = True\n",
    "        self.cached_regions = dict()\n",
    "        self.level_n = level_n\n",
    "\n",
    "    def _get_regions(self, h: int, w: int) -> List:\n",
    "        \"\"\"\n",
    "        Divide the image into several regions.\n",
    "        Args:\n",
    "            h (int): height for dividing regions.\n",
    "            w (int): width for dividing regions.\n",
    "        Returns:\n",
    "            regions (List): a list of region positions.\n",
    "        \"\"\"\n",
    "        if (h, w) in self.cached_regions:\n",
    "            return self.cached_regions[(h, w)]\n",
    "\n",
    "        m = 1\n",
    "        n_h, n_w = 1, 1\n",
    "        regions = list()\n",
    "        if h != w:\n",
    "            min_edge = min(h, w)\n",
    "            left_space = max(h, w) - min(h, w)\n",
    "            iou_target = 0.4\n",
    "            iou_best = 1.0\n",
    "            while True:\n",
    "                iou_tmp = (min_edge ** 2 - min_edge * (left_space // m)) / (min_edge ** 2)\n",
    "\n",
    "                # small m maybe result in non-overlap\n",
    "                if iou_tmp <= 0:\n",
    "                    m += 1\n",
    "                    continue\n",
    "\n",
    "                if abs(iou_tmp - iou_target) <= iou_best:\n",
    "                    iou_best = abs(iou_tmp - iou_target)\n",
    "                    m += 1\n",
    "                else:\n",
    "                    break\n",
    "            if h < w:\n",
    "                n_w = m\n",
    "            else:\n",
    "                n_h = m\n",
    "\n",
    "        for i in range(self.level_n):\n",
    "            region_width = int(2 * 1.0 / (i + 2) * min(h, w))\n",
    "            step_size_h = (h - region_width) // n_h\n",
    "            step_size_w = (w - region_width) // n_w\n",
    "\n",
    "            for x in range(n_h):\n",
    "                for y in range(n_w):\n",
    "                    st_x = step_size_h * x\n",
    "                    ed_x = st_x + region_width - 1\n",
    "                    assert ed_x < h\n",
    "                    st_y = step_size_w * y\n",
    "                    ed_y = st_y + region_width - 1\n",
    "                    assert ed_y < w\n",
    "                    regions.append((st_x, st_y, ed_x, ed_y))\n",
    "\n",
    "            n_h += 1\n",
    "            n_w += 1\n",
    "\n",
    "        self.cached_regions[(h, w)] = regions\n",
    "        return regions\n",
    "\n",
    "    def forward(self, fea:torch.tensor) -> torch.tensor:\n",
    "        final_fea = None\n",
    "        if fea.ndimension() == 4:\n",
    "            h, w = fea.shape[2:]       \n",
    "            regions = self._get_regions(h, w)\n",
    "            for _, r in enumerate(regions):\n",
    "                st_x, st_y, ed_x, ed_y = r\n",
    "                region_fea = (fea[:, :, st_x: ed_x, st_y: ed_y].max(dim=3)[0]).max(dim=2)[0]#max-pooling\n",
    "                region_fea = region_fea / torch.norm(region_fea, dim=1, keepdim=True)#PCA-whitening\n",
    "                if final_fea is None:\n",
    "                    final_fea = region_fea\n",
    "                else:\n",
    "                    final_fea = final_fea + region_fea\n",
    "        else:# In case of fc feature.\n",
    "            assert fea.ndimension() == 2\n",
    "            if self.first_show:\n",
    "                print(\"[RMAC Aggregator]: find 2-dimension feature map, skip aggregation\")\n",
    "                self.first_show = False\n",
    "            final_fea = fea\n",
    "        return final_fea\n",
    "    \n",
    "class CircleLoss(nn.Module):\n",
    "    def __init__(self, scale=32, margin=0.25, similarity='cos', **kwargs):\n",
    "        super(CircleLoss, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.similarity = similarity\n",
    "        \n",
    "    def forward(self, feats, labels):\n",
    "        assert feats.size(0) == labels.size(0), \\\n",
    "            f\"feats.size(0): {feats.size(0)} is not equal to labels.size(0): {labels.size(0)}\"\n",
    "        batch_size = feats.size(0)\n",
    "        if self.similarity == 'dot':\n",
    "            sim_mat = torch.matmul(feats, torch.t(feats))\n",
    "        elif self.similarity == 'cos':\n",
    "            feats = F.normalize(feats)\n",
    "            sim_mat = feats.mm(feats.t())\n",
    "        else:\n",
    "            raise ValueError('This similarity is not implemented.')\n",
    "        loss = list()\n",
    "        for i in range(batch_size):\n",
    "            pos_index = labels == labels[i]\n",
    "            pos_index[i] = 0\n",
    "            neg_index = labels != labels[i]\n",
    "            pos_pair_ = sim_mat[i][pos_index]\n",
    "            neg_pair_ = sim_mat[i][neg_index]\n",
    "\n",
    "            alpha_p = torch.relu(-pos_pair_ + 1 + self.margin)\n",
    "            alpha_n = torch.relu(neg_pair_ + self.margin)\n",
    "            margin_p = 1 - self.margin\n",
    "            margin_n = self.margin\n",
    "            loss_p = torch.sum(torch.exp(-self.scale * alpha_p * (pos_pair_ - margin_p)))\n",
    "            loss_n = torch.sum(torch.exp(self.scale * alpha_n * (neg_pair_ - margin_n)))\n",
    "            loss.append(torch.log(1 + loss_p * loss_n))\n",
    "\n",
    "        loss = sum(loss) / batch_size\n",
    "        return loss\n",
    "    \n",
    "class YNetLoss(nn.Module):\n",
    "    def __init__(self, lr=0.001):\n",
    "        super(YNetLoss, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.FloatTensor([0.01]))\n",
    "        #self.beta = nn.Parameter(torch.FloatTensor([1.0]))\n",
    "        #self.l1_reg = nn.Parameter(F.normalize(torch.tensor([torch.abs(self.alpha), torch.abs(self.beta)]), p=1, dim=0))\n",
    "        self.lr = lr #weight_decay\n",
    "        \n",
    "    def forward(self,clloss, celoss): \n",
    "        #l2_reg = self.lr* (torch.norm(torch.abs(self.alpha), p=2) + torch.norm(torch.abs(1-self.alpha), p=2))\n",
    "        #l2_reg = self.lr* (torch.norm(torch.abs(self.alpha), p=2)\n",
    "        loss = torch.abs(self.alpha)*clloss + torch.abs(1-self.alpha)*celoss #+ l2_reg\n",
    "        return loss\n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class YNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks=[2,2,2,2], n_classes=2, code_size=64):\n",
    "        super(YNet, self).__init__()\n",
    "        # Bottom-up layers，classifcation loss\n",
    "        self.in_planes = 8  #3 D->64 channels\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.layer2 = self._make_layer(block, 8, num_blocks[0], stride=1)\n",
    "        self.layer3 = self._make_layer(block, 16, num_blocks[1], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 32, num_blocks[2], stride=2)\n",
    "        self.layer5 = self._make_layer(block, 64, num_blocks[3], stride=2)\n",
    "        self.conv6 = nn.Conv2d(256, 32, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        #self.fc1 = nn.Linear(32*4*4, code_size)#code_size:length of hash code\n",
    "        self.fc1 = nn.Linear(256*8*8, code_size)\n",
    "        self.fc2 = nn.Linear(code_size, n_classes) #num_classes:number of classes\n",
    "        \n",
    "        # Top-down layer, segmentation loss\n",
    "        self.toplayer = nn.Conv2d(256, 32, kernel_size=1, stride=1, padding=0)  # Reduce channels\n",
    "        \n",
    "        self.latlayer1 = nn.Conv2d(128, 32, kernel_size=1, stride=1, padding=0)# Lateral layers\n",
    "        self.latlayer2 = nn.Conv2d(64, 32, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.upsample = nn.Upsample((256,256), mode='bilinear',align_corners=True)\n",
    "        self.conv7 = nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(3)#mask 0,1,2\n",
    "        \n",
    "        # Hash layer, ranking loss\n",
    "        self.conv8 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.r_mac_pool = RMAC(level_n=3) \n",
    "        self.l2norm = L2Normalization()\n",
    "        self.fc3 = nn.Linear(512, n_classes) #num_classes:number of classes\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _upsample_add(self, x, y):\n",
    "        '''Upsample and add two feature maps.\n",
    "        Args:\n",
    "          x: (Variable) top feature map to be upsampled.\n",
    "          y: (Variable) lateral feature map.\n",
    "        Returns:\n",
    "          (Variable) added feature map.\n",
    "        Note in PyTorch, when input size is odd, the upsampled feature map\n",
    "        with `F.upsample(..., scale_factor=2, mode='nearest')`\n",
    "        maybe not equal to the lateral feature map size.\n",
    "        e.g.\n",
    "        original input size: [N,_,15,15] ->\n",
    "        conv2d feature map size: [N,_,8,8] ->\n",
    "        upsampled feature map size: [N,_,16,16]\n",
    "        So we choose bilinear upsample which supports arbitrary output sizes.\n",
    "        '''\n",
    "        _,_,H,W = y.size()\n",
    "        return F.upsample(x, size=(H,W), mode='bilinear') + y\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Bottom-up, classifcation loss\n",
    "        h1 = F.relu(self.bn1(self.conv1(x)))#(3,256,256)->(8,128,128)\n",
    "        h1 = F.max_pool2d(h1, kernel_size=3, stride=2, padding=1)#(8,128,128)->(8,64,64)\n",
    "        \n",
    "        h2 = self.layer2(h1)#(8,64,64)->(32,64,64)\n",
    "        h3 = self.layer3(h2)#(32,64,64)->(64,32,32)\n",
    "        h4 = self.layer4(h3)#(64,32,32)->(128,16,16)\n",
    "        h5 = self.layer5(h4)#(128,16,16)->(256,8,8)\n",
    "        \n",
    "        #h6 = self.conv6(h5)#(256,8,8)->(32,4,4) \n",
    "        h6 = h5.view(h5.size(0), -1)#conv->linear\n",
    "        h_feat = self.fc1(h6)\n",
    "        h_cls = self.fc2(h_feat)\n",
    "        \n",
    "        # Top-down, segmentation loss\n",
    "        s5 = self.toplayer(h5)#(256,8,8)->(32,8,8)\n",
    "        s4 = self._upsample_add(s5, self.latlayer1(h4))#{(32,8,8),(32, 16, 16)}->(32, 16, 16)\n",
    "        s3 = self._upsample_add(s4, self.latlayer2(h3))#{(32, 16, 16),(32, 32, 32)}->(32, 32, 32)\n",
    "        s2 = self._upsample_add(s3, h2) #{(32, 32, 32),(32, 64, 64)}->(32, 64, 64)\n",
    "        \n",
    "        s1 = self.upsample(s2)#(32, 64, 64)->(32, 256, 256)\n",
    "        s_mask = self.bn2(self.conv7(s1))#(32, 256, 256)->(3, 256, 256)\n",
    "        \n",
    "        #Hash, ranking loss\n",
    "        c5 = self.conv8(h5)#(256,8,8)->(512,8,8)\n",
    "        \n",
    "        c4 = self.r_mac_pool(c5) \n",
    "        \n",
    "        c_feat = self.l2norm(c4) #512\n",
    "        c_cls = self.fc3(c_feat)\n",
    "\n",
    "        return h_feat, h_cls, s_mask, c_feat, c_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59 / 59 : loss = 12.150268Eopch:     1 mean_loss = 18.048010\n",
      " 59 / 59 : loss = 12.083676Eopch:     2 mean_loss = 15.162417\n",
      " 59 / 59 : loss = 0.1391056Eopch:     3 mean_loss = 15.317901\n",
      " 59 / 59 : loss = 11.990962Eopch:     4 mean_loss = 13.101860\n",
      " 59 / 59 : loss = 8.9732631Eopch:     5 mean_loss = 11.495081\n",
      " 59 / 59 : loss = 9.4529819Eopch:     6 mean_loss = 10.999982\n",
      " 59 / 59 : loss = 6.0537978Eopch:     7 mean_loss = 9.958940\n",
      " 59 / 59 : loss = 6.6876542Eopch:     8 mean_loss = 9.151453\n",
      " 59 / 59 : loss = 7.3852717Eopch:     9 mean_loss = 8.339525\n",
      " 59 / 59 : loss = 6.323889Eopch:    10 mean_loss = 7.442982\n",
      "best_loss = 7.442982\n",
      " 6 / 7 9 Completed buliding index in 1 seconds\n",
      "mAP@5=0.6226\n",
      "mAP@10=0.5642\n",
      "mAP@20=0.5346\n",
      "mAP@50=0.4980\n",
      "mIoU=0.9849\n",
      "Accuracy: 0.461538\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "model = YNet(block=Bottleneck).cuda()#initialize model\n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #for segmentation\n",
    "cl_loss = CircleLoss().cuda() #for classification\n",
    "ynet_loss = YNetLoss().cuda()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "optimizer = torch.optim.Adam([{'params':model.parameters()},{'params':ynet_loss.parameters()}], lr=0.001)\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trY)))\n",
    "    on_trI = np.array(trI)[shuffled_idx]\n",
    "    on_trM = np.array(trM)[shuffled_idx]\n",
    "    on_trY = np.array(trY)[shuffled_idx]\n",
    "    num_batches = len(trY) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(on_trI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(on_trY[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        m_batch = torch.from_numpy(on_trM[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        h_feat, h_cls, s_mask, c_feat, c_cls = model(I_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        #loss\n",
    "        mask_loss = ce_loss(s_mask, m_batch)\n",
    "        #mask_loss.backward(retain_graph=True)\n",
    "        cls_loss =  cl_loss(c_feat, y_batch) #ce_loss(c_cls, y_batch)\n",
    "        #cls_loss.backward()\n",
    "        loss = ynet_loss(mask_loss, cls_loss)\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#hash code of train data \n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize +1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, _, _, _, _ = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    trF.extend(x_hash.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data\n",
    "teF = []\n",
    "teM_pred = []\n",
    "teY_pred = []\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, _, x_mask, _, x_cls = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(x_hash.cpu().data.numpy().tolist()) #record feature\n",
    "    x_mask = F.log_softmax(x_mask,dim=1) \n",
    "    m_pred = x_mask.max(1,keepdim=True)[1]\n",
    "    teM_pred.extend(m_pred.cpu().data.numpy().tolist())\n",
    "    x_cls = F.log_softmax(x_cls,dim=1) \n",
    "    y_pred = x_cls.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(y_pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(64) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#retrieval performance\n",
    "for topk in [5,10,20,50]:\n",
    "    mAP = [] #mean average precision\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "    print(\"mAP@{}={:.4f}\".format(topk, np.mean(mAP)))\n",
    "#segementation performance  \n",
    "mIoU=[]\n",
    "for i in range(len(teM)):\n",
    "    a = teM[i]\n",
    "    b = np.array(teM_pred[i][0])\n",
    "    #iou_score = np.where(abs(a.flatten()-b.flatten())<0.5,1,0)\n",
    "    #iou_score = np.where(a.flatten()==b.flatten(),1,0)\n",
    "    iou_score = a == b\n",
    "    mIoU.append(np.mean(iou_score))\n",
    "print(\"mIoU={:.4f}\".format(np.mean(mIoU)))\n",
    "#classification performance\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59 / 59 : loss = 17.709658Eopch:     1 mean_loss = 21.683000\n",
      " 59 / 59 : loss = 18.718557Eopch:     2 mean_loss = 16.737897\n",
      " 59 / 59 : loss = 9.8149292Eopch:     3 mean_loss = 15.190897\n",
      " 59 / 59 : loss = 11.241364Eopch:     4 mean_loss = 13.391131\n",
      " 59 / 59 : loss = 8.5942954Eopch:     5 mean_loss = 12.072199\n",
      " 59 / 59 : loss = 7.3272264Eopch:     6 mean_loss = 11.407120\n",
      " 59 / 59 : loss = 9.7321466Eopch:     7 mean_loss = 9.939303\n",
      " 59 / 59 : loss = 8.5178936Eopch:     8 mean_loss = 9.636747\n",
      " 59 / 59 : loss = 8.3417545Eopch:     9 mean_loss = 8.613822\n",
      " 59 / 59 : loss = 5.2925659Eopch:    10 mean_loss = 7.841102\n",
      " 59 / 59 : loss = 6.472335Eopch:    11 mean_loss = 7.153463\n",
      " 59 / 59 : loss = 0.178604Eopch:    12 mean_loss = 6.021548\n",
      " 59 / 59 : loss = 4.894056Eopch:    13 mean_loss = 5.372691\n",
      " 59 / 59 : loss = 3.525739Eopch:    14 mean_loss = 4.416241\n",
      " 59 / 59 : loss = 2.393178Eopch:    15 mean_loss = 3.625309\n",
      " 59 / 59 : loss = 1.895753Eopch:    16 mean_loss = 2.778874\n",
      " 59 / 59 : loss = 1.193534Eopch:    17 mean_loss = 1.929253\n",
      " 59 / 59 : loss = 0.141497Eopch:    18 mean_loss = 1.203653\n",
      " 59 / 59 : loss = 0.164984Eopch:    19 mean_loss = 0.411425\n",
      " 59 / 59 : loss = 0.124661Eopch:    20 mean_loss = 0.138108\n",
      " 59 / 59 : loss = 0.116585Eopch:    21 mean_loss = 0.122260\n",
      " 59 / 59 : loss = 0.106502Eopch:    22 mean_loss = 0.113442\n",
      " 59 / 59 : loss = 0.099567Eopch:    23 mean_loss = 0.106507\n",
      " 59 / 59 : loss = 0.098845Eopch:    24 mean_loss = 0.099742\n",
      " 59 / 59 : loss = 0.093535Eopch:    25 mean_loss = 0.095304\n",
      " 59 / 59 : loss = 0.084273Eopch:    26 mean_loss = 0.089416\n",
      " 59 / 59 : loss = 0.079435Eopch:    27 mean_loss = 0.084576\n",
      " 59 / 59 : loss = 0.084976Eopch:    28 mean_loss = 0.081205\n",
      " 59 / 59 : loss = 0.073981Eopch:    29 mean_loss = 0.076196\n",
      " 59 / 59 : loss = 0.067879Eopch:    30 mean_loss = 0.072564\n",
      " 59 / 59 : loss = 0.065131Eopch:    31 mean_loss = 0.069887\n",
      " 59 / 59 : loss = 0.060998Eopch:    32 mean_loss = 0.068039\n",
      " 59 / 59 : loss = 0.061223Eopch:    33 mean_loss = 0.063610\n",
      " 59 / 59 : loss = 0.065071Eopch:    34 mean_loss = 0.061522\n",
      " 59 / 59 : loss = 0.057451Eopch:    35 mean_loss = 0.059152\n",
      " 59 / 59 : loss = 0.059829Eopch:    36 mean_loss = 0.056514\n",
      " 59 / 59 : loss = 0.052929Eopch:    37 mean_loss = 0.054567\n",
      " 59 / 59 : loss = 0.060068Eopch:    38 mean_loss = 0.054663\n",
      " 59 / 59 : loss = 0.046857Eopch:    39 mean_loss = 0.051566\n",
      " 59 / 59 : loss = 0.045306Eopch:    40 mean_loss = 0.050105\n",
      " 59 / 59 : loss = 0.047052Eopch:    41 mean_loss = 0.047932\n",
      " 59 / 59 : loss = 0.040162Eopch:    42 mean_loss = 0.047095\n",
      " 59 / 59 : loss = 0.042193Eopch:    43 mean_loss = 0.044719\n",
      " 59 / 59 : loss = 0.043558Eopch:    44 mean_loss = 0.044260\n",
      " 59 / 59 : loss = 0.041559Eopch:    45 mean_loss = 0.044514\n",
      " 59 / 59 : loss = 0.038448Eopch:    46 mean_loss = 0.042123\n",
      " 59 / 59 : loss = 0.038363Eopch:    47 mean_loss = 0.040237\n",
      " 59 / 59 : loss = 0.033978Eopch:    48 mean_loss = 0.040079\n",
      " 59 / 59 : loss = 0.032813Eopch:    49 mean_loss = 0.038015\n",
      " 59 / 59 : loss = 0.033154Eopch:    50 mean_loss = 0.038098\n",
      "best_loss = 0.038015\n",
      " 6 / 7 9 Completed buliding index in 1 seconds\n",
      "mAP@5=0.6131\n",
      "mAP@10=0.5710\n",
      "mAP@20=0.5309\n",
      "mAP@50=0.4883\n",
      "mIoU=0.9933\n",
      "Accuracy: 0.461538\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "model = YNet(block=Bottleneck).cuda()#initialize model\n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #for segmentation\n",
    "cl_loss = CircleLoss().cuda() #for classification\n",
    "ynet_loss = YNetLoss().cuda()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "optimizer = torch.optim.Adam([{'params':model.parameters()},{'params':ynet_loss.parameters()}], lr=0.001)\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "couple_loss, sum_loss, cls_loss, seg_loss = [], [], [], []\n",
    "batchSize = 10\n",
    "for epoch in range(50):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trY)))\n",
    "    on_trI = np.array(trI)[shuffled_idx]\n",
    "    on_trM = np.array(trM)[shuffled_idx]\n",
    "    on_trY = np.array(trY)[shuffled_idx]\n",
    "    num_batches = len(trY) // batchSize + 1\n",
    "    couple_loss_b, sum_loss_b, cls_loss_b, seg_loss_b = [], [], [], []\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(on_trI[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(on_trY[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        m_batch = torch.from_numpy(on_trM[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        h_feat, h_cls, s_mask, c_feat, c_cls = model(I_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        #loss\n",
    "        mask_loss = ce_loss(s_mask, m_batch)\n",
    "        seg_loss_b.append(mask_loss.item())\n",
    "        #mask_loss.backward(retain_graph=True)\n",
    "        label_loss =  cl_loss(c_feat, y_batch) #ce_loss(c_cls, y_batch)\n",
    "        cls_loss_b.append(label_loss.item())\n",
    "        sum_loss_b.append(mask_loss.item()+label_loss.item())\n",
    "        #cls_loss.backward()\n",
    "        loss = ynet_loss(mask_loss, label_loss)\n",
    "        couple_loss_b.append(loss.item())\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "    cls_loss.append(np.mean(cls_loss_b))\n",
    "    seg_loss.append(np.mean(seg_loss_b))\n",
    "    sum_loss.append(np.mean(sum_loss_b))\n",
    "    couple_loss.append(np.mean(couple_loss_b))\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#hash code of train data \n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize +1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, _, _, _, _ = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    trF.extend(x_hash.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data\n",
    "teF = []\n",
    "teM_pred = []\n",
    "teY_pred = []\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, _, x_mask, _, x_cls = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(x_hash.cpu().data.numpy().tolist()) #record feature\n",
    "    x_mask = F.log_softmax(x_mask,dim=1) \n",
    "    m_pred = x_mask.max(1,keepdim=True)[1]\n",
    "    teM_pred.extend(m_pred.cpu().data.numpy().tolist())\n",
    "    x_cls = F.log_softmax(x_cls,dim=1) \n",
    "    y_pred = x_cls.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(y_pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(64) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#retrieval performance\n",
    "for topk in [5,10,20,50]:\n",
    "    mAP = [] #mean average precision\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "    print(\"mAP@{}={:.4f}\".format(topk, np.mean(mAP)))\n",
    "#segementation performance  \n",
    "mIoU=[]\n",
    "for i in range(len(teM)):\n",
    "    a = teM[i]\n",
    "    b = np.array(teM_pred[i][0])\n",
    "    #iou_score = np.where(abs(a.flatten()-b.flatten())<0.5,1,0)\n",
    "    #iou_score = np.where(a.flatten()==b.flatten(),1,0)\n",
    "    iou_score = a == b\n",
    "    mIoU.append(np.mean(iou_score))\n",
    "print(\"mIoU={:.4f}\".format(np.mean(mIoU)))\n",
    "#classification performance\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.682999927297992, 16.737896655449422, 15.1908966979738, 13.391131098240109, 12.07219904358104, 11.407120096481453, 9.939303473143255, 9.636746762920234, 8.613822262923597, 7.841101626976061, 7.153462843117067, 6.021548044378474, 5.372691410577904, 4.416240615107245, 3.625308961181317, 2.778873702227059, 1.9292534971136157, 1.2036534418999139, 0.4114252033375077, 0.13810823226379135, 0.1222600468387038, 0.11344211826385078, 0.10650655589366363, 0.09974170829785073, 0.09530373965784655, 0.08941562600054984, 0.08457606576256833, 0.08120491658732043, 0.07619576762288303, 0.07256394877272138, 0.0698865542219857, 0.06803886497677383, 0.06360979157231622, 0.0615219477627237, 0.05915247933086702, 0.05651354082560135, 0.05456652170268156, 0.0546632464028011, 0.05156598574781822, 0.05010486375224792, 0.04793167158456172, 0.04709497144666769, 0.04471903673167956, 0.0442596430874477, 0.04451406683962224, 0.04212263794773716, 0.04023681953549385, 0.040079236220000154, 0.03801465268104763, 0.03809762828178325]\n"
     ]
    }
   ],
   "source": [
    "print(couple_loss)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Normalization(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we construct three nn.Linear instances that we will use\n",
    "        in the forward pass.\n",
    "        \"\"\"\n",
    "        super(L2Normalization, self).__init__()\n",
    "        self.eps = 1e-8\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.is_cuda:\n",
    "            caped_eps = Variable(torch.Tensor([self.eps])).cuda(torch.cuda.device_of(x).idx)\n",
    "        else:\n",
    "            caped_eps = Variable(torch.Tensor([self.eps]))\n",
    "        x = torch.div(x.transpose(0,1),x.max(1)[0]).transpose(0,1) # max_normed\n",
    "        norm = torch.norm(x,2,1) + caped_eps.expand(x.size()[0])\n",
    "        y = torch.div(x.transpose(0,1),norm).transpose(0,1)\n",
    "        return y\n",
    "    \n",
    "class RMAC(nn.Module):\n",
    "    \"\"\"\n",
    "    Regional Maximum activation of convolutions (R-MAC).\n",
    "    c.f. https://arxiv.org/pdf/1511.05879.pdf\n",
    "    Args:\n",
    "        level_n (int): number of levels for selecting regions.\n",
    "    \"\"\"\n",
    "    def __init__(self,level_n:int):\n",
    "        super(RMAC, self).__init__()\n",
    "        self.first_show = True\n",
    "        self.cached_regions = dict()\n",
    "        self.level_n = level_n\n",
    "\n",
    "    def _get_regions(self, h: int, w: int) -> List:\n",
    "        \"\"\"\n",
    "        Divide the image into several regions.\n",
    "        Args:\n",
    "            h (int): height for dividing regions.\n",
    "            w (int): width for dividing regions.\n",
    "        Returns:\n",
    "            regions (List): a list of region positions.\n",
    "        \"\"\"\n",
    "        if (h, w) in self.cached_regions:\n",
    "            return self.cached_regions[(h, w)]\n",
    "\n",
    "        m = 1\n",
    "        n_h, n_w = 1, 1\n",
    "        regions = list()\n",
    "        if h != w:\n",
    "            min_edge = min(h, w)\n",
    "            left_space = max(h, w) - min(h, w)\n",
    "            iou_target = 0.4\n",
    "            iou_best = 1.0\n",
    "            while True:\n",
    "                iou_tmp = (min_edge ** 2 - min_edge * (left_space // m)) / (min_edge ** 2)\n",
    "\n",
    "                # small m maybe result in non-overlap\n",
    "                if iou_tmp <= 0:\n",
    "                    m += 1\n",
    "                    continue\n",
    "\n",
    "                if abs(iou_tmp - iou_target) <= iou_best:\n",
    "                    iou_best = abs(iou_tmp - iou_target)\n",
    "                    m += 1\n",
    "                else:\n",
    "                    break\n",
    "            if h < w:\n",
    "                n_w = m\n",
    "            else:\n",
    "                n_h = m\n",
    "\n",
    "        for i in range(self.level_n):\n",
    "            region_width = int(2 * 1.0 / (i + 2) * min(h, w))\n",
    "            step_size_h = (h - region_width) // n_h\n",
    "            step_size_w = (w - region_width) // n_w\n",
    "\n",
    "            for x in range(n_h):\n",
    "                for y in range(n_w):\n",
    "                    st_x = step_size_h * x\n",
    "                    ed_x = st_x + region_width - 1\n",
    "                    assert ed_x < h\n",
    "                    st_y = step_size_w * y\n",
    "                    ed_y = st_y + region_width - 1\n",
    "                    assert ed_y < w\n",
    "                    regions.append((st_x, st_y, ed_x, ed_y))\n",
    "\n",
    "            n_h += 1\n",
    "            n_w += 1\n",
    "\n",
    "        self.cached_regions[(h, w)] = regions\n",
    "        return regions\n",
    "\n",
    "    def forward(self, fea:torch.tensor) -> torch.tensor:\n",
    "        final_fea = None\n",
    "        if fea.ndimension() == 4:\n",
    "            h, w = fea.shape[2:]       \n",
    "            regions = self._get_regions(h, w)\n",
    "            for _, r in enumerate(regions):\n",
    "                st_x, st_y, ed_x, ed_y = r\n",
    "                region_fea = (fea[:, :, st_x: ed_x, st_y: ed_y].max(dim=3)[0]).max(dim=2)[0]#max-pooling\n",
    "                region_fea = region_fea / torch.norm(region_fea, dim=1, keepdim=True)#PCA-whitening\n",
    "                if final_fea is None:\n",
    "                    final_fea = region_fea\n",
    "                else:\n",
    "                    final_fea = final_fea + region_fea\n",
    "        else:# In case of fc feature.\n",
    "            assert fea.ndimension() == 2\n",
    "            if self.first_show:\n",
    "                print(\"[RMAC Aggregator]: find 2-dimension feature map, skip aggregation\")\n",
    "                self.first_show = False\n",
    "            final_fea = fea\n",
    "        return final_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/luyajie/triplet-deep-hash-pytorch#triplet-deep-hash-pytorch            \n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self,H_q,H_p,H_n):    \n",
    "        margin_val = self.margin * H_q.shape[1]\n",
    "        squared_loss_pos = torch.mean(self.mse_loss(H_q, H_p), dim=1)\n",
    "        squared_loss_neg = torch.mean(self.mse_loss(H_q, H_n), dim=1)\n",
    "        zeros = torch.zeros_like(squared_loss_neg)\n",
    "        loss  = torch.max(zeros, margin_val - squared_loss_neg + squared_loss_pos)\n",
    "        return torch.mean(loss)\n",
    "    \n",
    "\n",
    "class CircleLoss(nn.Module):\n",
    "    def __init__(self, scale=32, margin=0.25, similarity='cos', **kwargs):\n",
    "        super(CircleLoss, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.similarity = similarity\n",
    "\n",
    "    def forward(self, feats, labels):\n",
    "        assert feats.size(0) == labels.size(0), \\\n",
    "            f\"feats.size(0): {feats.size(0)} is not equal to labels.size(0): {labels.size(0)}\"\n",
    "        batch_size = feats.size(0)\n",
    "        if self.similarity == 'dot':\n",
    "            sim_mat = torch.matmul(feats, torch.t(feats))\n",
    "        elif self.similarity == 'cos':\n",
    "            feats = F.normalize(feats)\n",
    "            sim_mat = feats.mm(feats.t())\n",
    "        else:\n",
    "            raise ValueError('This similarity is not implemented.')\n",
    "        loss = list()\n",
    "        for i in range(batch_size):\n",
    "            pos_index = labels == labels[i]\n",
    "            pos_index[i] = 0\n",
    "            neg_index = labels != labels[i]\n",
    "            pos_pair_ = sim_mat[i][pos_index]\n",
    "            neg_pair_ = sim_mat[i][neg_index]\n",
    "\n",
    "            alpha_p = torch.relu(-pos_pair_ + 1 + self.margin)\n",
    "            alpha_n = torch.relu(neg_pair_ + self.margin)\n",
    "            margin_p = 1 - self.margin\n",
    "            margin_n = self.margin\n",
    "            loss_p = torch.sum(torch.exp(-self.scale * alpha_p * (pos_pair_ - margin_p)))\n",
    "            loss_n = torch.sum(torch.exp(self.scale * alpha_n * (neg_pair_ - margin_n)))\n",
    "            loss.append(torch.log(1 + loss_p * loss_n))\n",
    "\n",
    "        loss = sum(loss) / batch_size\n",
    "        return loss\n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class NNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks=[2,2,2,2], n_classes=2, code_size=64):\n",
    "        super(NNet, self).__init__()\n",
    "        # Bottom-up layers，classifcation loss\n",
    "        self.in_planes = 8  #3 D->64 channels\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.layer2 = self._make_layer(block, 8, num_blocks[0], stride=1)\n",
    "        self.layer3 = self._make_layer(block, 16, num_blocks[1], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 32, num_blocks[2], stride=2)\n",
    "        self.layer5 = self._make_layer(block, 64, num_blocks[3], stride=2)\n",
    "        self.conv6 = nn.Conv2d(256, 32, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32*4*4, code_size)#code_size:length of hash code\n",
    "        self.fc2 = nn.Linear(code_size, n_classes) #num_classes:number of classes\n",
    "        \n",
    "        # Top-down layer, segmentation loss\n",
    "        self.toplayer = nn.Conv2d(256, 32, kernel_size=1, stride=1, padding=0)  # Reduce channels\n",
    "        \n",
    "        self.latlayer1 = nn.Conv2d(128, 32, kernel_size=1, stride=1, padding=0)# Lateral layers\n",
    "        self.latlayer2 = nn.Conv2d(64, 32, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.upsample = nn.Upsample((256,256), mode='bilinear',align_corners=True)\n",
    "        self.conv7 = nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(3)#mask 0,1,2\n",
    "        \n",
    "        # Hash layer, ranking loss\n",
    "        self.conv8 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.r_mac_pool = RMAC(level_n=3) \n",
    "        self.l2norm = L2Normalization()\n",
    "        self.fc3 = nn.Linear(512, n_classes) #num_classes:number of classes\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _upsample_add(self, x, y):\n",
    "        '''Upsample and add two feature maps.\n",
    "        Args:\n",
    "          x: (Variable) top feature map to be upsampled.\n",
    "          y: (Variable) lateral feature map.\n",
    "        Returns:\n",
    "          (Variable) added feature map.\n",
    "        Note in PyTorch, when input size is odd, the upsampled feature map\n",
    "        with `F.upsample(..., scale_factor=2, mode='nearest')`\n",
    "        maybe not equal to the lateral feature map size.\n",
    "        e.g.\n",
    "        original input size: [N,_,15,15] ->\n",
    "        conv2d feature map size: [N,_,8,8] ->\n",
    "        upsampled feature map size: [N,_,16,16]\n",
    "        So we choose bilinear upsample which supports arbitrary output sizes.\n",
    "        '''\n",
    "        _,_,H,W = y.size()\n",
    "        return F.upsample(x, size=(H,W), mode='bilinear') + y\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Bottom-up, classifcation loss\n",
    "        h1 = F.relu(self.bn1(self.conv1(x)))#(3,256,256)->(8,128,128)\n",
    "        h1 = F.max_pool2d(h1, kernel_size=3, stride=2, padding=1)#(8,128,128)->(8,64,64)\n",
    "        \n",
    "        h2 = self.layer2(h1)#(8,64,64)->(32,64,64)\n",
    "        h3 = self.layer3(h2)#(32,64,64)->(64,32,32)\n",
    "        h4 = self.layer4(h3)#(64,32,32)->(128,16,16)\n",
    "        h5 = self.layer5(h4)#(128,16,16)->(256,8,8)\n",
    "        \n",
    "        h6 = self.conv6(h5)#(256,8,8)->(32,4,4) \n",
    "        h6 = h6.view(h6.size(0), -1)#conv->linear\n",
    "        h_feat = self.fc1(h6)\n",
    "        h_cls = self.fc2(h_feat)\n",
    "        \n",
    "        # Top-down, segmentation loss\n",
    "        s5 = self.toplayer(h5)#(256,8,8)->(32,8,8)\n",
    "        s4 = self._upsample_add(s5, self.latlayer1(h4))#{(32,8,8),(32, 16, 16)}->(32, 16, 16)\n",
    "        s3 = self._upsample_add(s4, self.latlayer2(h3))#{(32, 16, 16),(32, 32, 32)}->(32, 32, 32)\n",
    "        s2 = self._upsample_add(s3, h2) #{(32, 32, 32),(32, 64, 64)}->(32, 64, 64)\n",
    "        \n",
    "        s1 = self.upsample(s2)#(32, 64, 64)->(32, 256, 256)\n",
    "        s_mask = self.bn2(self.conv7(s1))#(32, 256, 256)->(3, 256, 256)\n",
    "        \n",
    "        #Hash, ranking loss\n",
    "        c5 = self.conv8(h5)#(256,8,8)->(512,8,8)\n",
    "        \n",
    "        c4 = self.r_mac_pool(c5) \n",
    "        \n",
    "        c_feat = self.l2norm(c4) #512\n",
    "        c_cls = self.fc3(c_feat)\n",
    "\n",
    "        return h_feat, h_cls, s_mask, c_feat, c_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/root/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64])\n",
      "torch.Size([10, 2])\n",
      "torch.Size([10, 3, 256, 256])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "net = NNet(block=Bottleneck)\n",
    "fms = net(Variable(torch.randn(10,3,256,256)))\n",
    "for fm in fms:\n",
    "    print(fm.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59 / 59 : loss = 4.880024Eopch:     1 mean_loss = 5.116520\n",
      " 59 / 59 : loss = 4.726438Eopch:     2 mean_loss = 4.766091\n",
      " 59 / 59 : loss = 4.434066Eopch:     3 mean_loss = 4.546924\n",
      " 59 / 59 : loss = 3.893452Eopch:     4 mean_loss = 4.229842\n",
      " 59 / 59 : loss = 3.887613Eopch:     5 mean_loss = 3.974490\n",
      " 59 / 59 : loss = 3.662602Eopch:     6 mean_loss = 3.707605\n",
      " 59 / 59 : loss = 3.121555Eopch:     7 mean_loss = 3.329089\n",
      " 59 / 59 : loss = 2.480757Eopch:     8 mean_loss = 3.069819\n",
      " 59 / 59 : loss = 2.976347Eopch:     9 mean_loss = 2.792656\n",
      " 59 / 59 : loss = 2.936525Eopch:    10 mean_loss = 2.498283\n",
      "best_loss = 2.498283\n",
      " 6 / 7 9 Completed buliding index in 22 seconds\n",
      "mAP@5=0.6192\n",
      "mAP@10=0.5986\n",
      "mAP@20=0.5644\n",
      "mAP@50=0.5203\n",
      "mIoU=0.9830\n",
      "Accuracy: 0.784615\n"
     ]
    }
   ],
   "source": [
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs( ):\n",
    "    idx_sf = []\n",
    "    idx_0 = np.where( np.array(trY) == 0 ) #class 0\n",
    "    idx_0 = list(idx_0[0])\n",
    "    idx_sf.extend(idx_0)\n",
    "    idx_1 = np.where( np.array(trY) == 1 ) #class 1\n",
    "    idx_1 = list(idx_1[0])\n",
    "    idx_sf.extend(idx_1)\n",
    "    random.shuffle(idx_sf)   \n",
    "    trQ_sf, trP_sf, trN_sf = [], [], []\n",
    "    trQ_y, trP_y, trN_y = [], [], []\n",
    "    trQ_m, trP_m, trN_m = [], [], []\n",
    "    for iQ in idx_sf:\n",
    "        trQ_sf.append(trI[iQ])\n",
    "        trQ_y.append(trY[iQ])\n",
    "        trQ_m.append(trM[iQ])\n",
    "        if trY[iQ] == 0:\n",
    "            idx_tmp = idx_0.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            trP_m.append(trM[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_0))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "            trN_m.append(trM[iN[0]])\n",
    "        elif trY[iQ] == 1:\n",
    "            idx_tmp = idx_1.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            trP_m.append(trM[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_1))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "            trN_m.append(trM[iN[0]])\n",
    "        else: pass\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trQ_sf),len(idx_sf)))\n",
    "        sys.stdout.flush()\n",
    "    return np.array(trQ_sf),np.array(trP_sf),np.array(trN_sf), np.array(trQ_y), np.array(trP_y), np.array(trN_y), np.array(trQ_m), np.array(trP_m), np.array(trN_m)\n",
    "#sample  triplet labels\n",
    "trQ_sf, trP_sf, trN_sf, trQ_y, trP_y, trN_y, trQ_m, trP_m, trN_m = onlineGenImgPairs() \n",
    "assert (trQ_sf.shape==trP_sf.shape and trQ_sf.shape==trN_sf.shape)\n",
    "assert (trQ_y.shape==trP_y.shape and trQ_y.shape==trN_y.shape)\n",
    "assert (trQ_m.shape==trP_m.shape and trQ_m.shape==trN_m.shape)\n",
    "assert (np.mean(np.where((np.array(trQ_y)-np.array(trP_y))!=0,1,0))==0.0)\n",
    "assert (np.mean(np.where((np.array(trQ_y)-np.array(trN_y))!=0,1,0))==1.0)\n",
    "\n",
    "#define model\n",
    "model = NNet(block=Bottleneck).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "tl_loss  = TripletLoss(margin=0.5).cuda() #define TripletLoss \n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define ce mutli-classes #F.log_softmax+F.nll_loss\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trQ_sf)))\n",
    "    train_q = trQ_sf[shuffled_idx]\n",
    "    train_q_y = trQ_y[shuffled_idx]\n",
    "    train_q_m = trQ_m[shuffled_idx]\n",
    "    train_p = trP_sf[shuffled_idx]\n",
    "    train_p_y = trP_y[shuffled_idx]\n",
    "    train_p_m = trP_m[shuffled_idx]\n",
    "    train_n = trN_sf[shuffled_idx]\n",
    "    train_n_y = trN_y[shuffled_idx]\n",
    "    train_n_m = trN_m[shuffled_idx]\n",
    "    num_batches = len(trQ_sf) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trQ_sf), (i+1)*batchSize])\n",
    "        Q_batch = torch.from_numpy(train_q[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Q_y_batch = torch.from_numpy(train_q_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        Q_m_batch = torch.from_numpy(train_q_m[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        P_batch = torch.from_numpy(train_p[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        P_y_batch = torch.from_numpy(train_p_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        P_m_batch = torch.from_numpy(train_p_m[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        N_batch = torch.from_numpy(train_n[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        N_y_batch = torch.from_numpy(train_n_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        N_m_batch = torch.from_numpy(train_n_m[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        Q_h_feat, Q_h_cls, Q_s_mask, Q_c_feat, Q_c_cls = model(Q_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        P_h_feat, P_h_cls, P_s_mask, P_c_feat, P_c_cls = model(P_batch.permute(0, 3, 1, 2))\n",
    "        N_h_feat, N_h_cls, N_s_mask, N_c_feat, N_c_cls = model(N_batch.permute(0, 3, 1, 2))\n",
    "        #loss\n",
    "        #rank_loss = tl_loss(Q_h_feat,P_h_feat,N_h_feat)\n",
    "        #rank_loss.backward()\n",
    "        mask_loss = ce_loss(Q_s_mask, Q_m_batch) + ce_loss(P_s_mask, P_m_batch) + ce_loss(N_s_mask, N_m_batch)\n",
    "        mask_loss.backward(retain_graph=True)\n",
    "        cls_loss = ce_loss(Q_c_cls, Q_y_batch) + ce_loss(P_c_cls, P_y_batch) + ce_loss(N_c_cls, N_y_batch)   \n",
    "        cls_loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        loss = cls_loss + mask_loss #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "model = model.cpu()#release gpu memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#hash code of train data \n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize +1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, _, _, _, _ = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    trF.extend(x_hash.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data\n",
    "teF = []\n",
    "teM_pred = []\n",
    "teY_pred = []\n",
    "num_batches = len(teY) // batchSize  +1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, _, x_mask, _, x_cls = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(x_hash.cpu().data.numpy().tolist()) #record feature\n",
    "    x_mask = F.log_softmax(x_mask,dim=1) \n",
    "    m_pred = x_mask.max(1,keepdim=True)[1]\n",
    "    teM_pred.extend(m_pred.cpu().data.numpy().tolist())\n",
    "    x_cls = F.log_softmax(x_cls,dim=1) \n",
    "    y_pred = x_cls.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(y_pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(64) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#retrieval performance\n",
    "for topk in [5,10,20,50]:\n",
    "    mAP = [] #mean average precision\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "    print(\"mAP@{}={:.4f}\".format(topk, np.mean(mAP)))\n",
    "#segementation performance  \n",
    "mIoU=[]\n",
    "for i in range(len(teM)):\n",
    "    a = teM[i]\n",
    "    b = np.array(teM_pred[i][0])\n",
    "    #iou_score = np.where(abs(a.flatten()-b.flatten())<0.5,1,0)\n",
    "    #iou_score = np.where(a.flatten()==b.flatten(),1,0)\n",
    "    iou_score = a == b\n",
    "    mIoU.append(np.mean(iou_score))\n",
    "print(\"mIoU={:.4f}\".format(np.mean(mIoU)))\n",
    "#classification performance\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "tl_loss=tl_loss.cpu()\n",
    "ce_loss=ce_loss.cpu()\n",
    "Q_batch = Q_batch.cpu()\n",
    "Q_y_batch = Q_y_batch.cpu()\n",
    "Q_m_batch = Q_m_batch.cpu()\n",
    "P_batch = P_batch.cpu()\n",
    "P_y_batch = P_y_batch.cpu()\n",
    "P_m_batch = P_m_batch.cpu()\n",
    "N_batch = N_batch.cpu()\n",
    "N_y_batch = N_y_batch.cpu()\n",
    "N_m_batch = N_m_batch.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\n"
     ]
    }
   ],
   "source": [
    "for name, param in ynet_loss.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
